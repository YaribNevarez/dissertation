\babel@toc {english}{}
\addvspace {10\p@ }
\contentsline {xchapter}{Introduction}{1}{chapter.1}%
\addvspace {10\p@ }
\contentsline {xchapter}{Background and Related Work}{15}{chapter.2}%
\contentsline {table}{\numberline {2.1}{\ignorespaces \gls {sbs} network architecture for handwritten digit classification task.\relax }}{19}{table.caption.16}%
\addvspace {10\p@ }
\contentsline {xchapter}{Accelerating Spike-by-Spike Neural Networks: Hybrid 8-bit Floating-Point and 4-bit Logarithmic Computation}{27}{chapter.3}%
\contentsline {table}{\numberline {3.1}{\ignorespaces Computation on embedded CPU.\relax }}{40}{table.caption.40}%
\contentsline {table}{\numberline {3.2}{\ignorespaces Performance of processing units with standard floating-point (IEEE 754) computation.\relax }}{42}{table.caption.44}%
\contentsline {table}{\numberline {3.3}{\ignorespaces Resource utilization and power dissipation of processing units with standard floating-point (IEEE 754) computation.\relax }}{44}{table.caption.47}%
\contentsline {table}{\numberline {3.4}{\ignorespaces Resource utilization and power dissipation of multiplier and adder floating-point (IEEE 754) operator cores.\relax }}{44}{table.caption.48}%
\contentsline {table}{\numberline {3.5}{\ignorespaces Resource utilization and power dissipation of processing units with hybrid custom floating-point approximation.\relax }}{48}{table.caption.54}%
\contentsline {table}{\numberline {3.6}{\ignorespaces Performance of hardware processing units with hybrid custom floating-point approximation.\relax }}{48}{table.caption.55}%
\contentsline {table}{\numberline {3.7}{\ignorespaces Performance of hardware processing units with hybrid logarithmic approximation.\relax }}{50}{table.caption.59}%
\contentsline {table}{\numberline {3.8}{\ignorespaces Resource utilization and power dissipation of processing units with hybrid logarithmic approximation.\relax }}{50}{table.caption.61}%
\contentsline {table}{\numberline {3.9}{\ignorespaces Experimental results.\relax }}{53}{table.caption.64}%
\contentsline {table}{\numberline {3.10}{\ignorespaces Platform implementations.\relax }}{53}{table.caption.66}%
\addvspace {10\p@ }
\contentsline {xchapter}{Accelerating Convolutional Neural Networks: Hybrid 6-bit Floating-Point Computation}{55}{chapter.4}%
\contentsline {table}{\numberline {4.1}{\ignorespaces Resource utilization and power dissipation on the Zynq-7007S SoC.\relax }}{77}{table.caption.101}%
\contentsline {table}{\numberline {4.2}{\ignorespaces Compute performance of the CPU and TP on each Conv2D tensor operation. This table presents: tensor operation, computational cost in mega floating-point operations (MFLOP), latency, throughput, power efficiency, and estimated energy consumption as the energy delay product (EDP).\relax }}{77}{table.caption.102}%
\contentsline {table}{\numberline {4.3}{\ignorespaces Resource utilization and power dissipation of individual multiplier and adder floating-point (IEEE 754) operator cores (Xilinx LogiCORE IP).\relax }}{78}{table.caption.104}%
\contentsline {table}{\numberline {4.4}{\ignorespaces Comparison of hardware implementation with related work.\relax }}{82}{table.caption.113}%
\addvspace {10\p@ }
\contentsline {xchapter}{Conclusion and Outlook}{85}{chapter.5}%
\addvspace {10\p@ }
\contentsline {xchapter}{Appendix}{89}{appendix.A}%
