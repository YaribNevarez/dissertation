\babel@toc {english}{}
\addvspace {10\p@ }
\contentsline {xchapter}{Introduction}{1}{chapter.1}%
\addvspace {10\p@ }
\contentsline {xchapter}{Background}{15}{chapter.2}%
\contentsline {table}{\numberline {2.1}{\ignorespaces \gls {sbs} network architecture for handwritten digit classification task.\relax }}{39}{table.caption.17}%
\addvspace {10\p@ }
\contentsline {xchapter}{Accelerating Spike-by-Spike Neural Networks: Hybrid 8-bit Floating-Point and 4-bit Logarithmic Computation}{43}{chapter.3}%
\contentsline {table}{\numberline {3.1}{\ignorespaces Computation on embedded CPU.\relax }}{58}{table.caption.33}%
\contentsline {table}{\numberline {3.2}{\ignorespaces Performance of processing units with standard floating-point (IEEE 754) computation.\relax }}{60}{table.caption.37}%
\contentsline {table}{\numberline {3.3}{\ignorespaces Resource utilization and power dissipation of processing units with standard floating-point (IEEE 754) computation.\relax }}{62}{table.caption.40}%
\contentsline {table}{\numberline {3.4}{\ignorespaces Resource utilization and power dissipation of multiplier and adder floating-point (IEEE 754) operator cores.\relax }}{62}{table.caption.41}%
\contentsline {table}{\numberline {3.5}{\ignorespaces Resource utilization and power dissipation of processing units with hybrid custom floating-point approximation.\relax }}{65}{table.caption.47}%
\contentsline {table}{\numberline {3.6}{\ignorespaces Performance of hardware processing units with hybrid custom floating-point approximation.\relax }}{66}{table.caption.48}%
\contentsline {table}{\numberline {3.7}{\ignorespaces Performance of hardware processing units with hybrid logarithmic approximation.\relax }}{68}{table.caption.52}%
\contentsline {table}{\numberline {3.8}{\ignorespaces Resource utilization and power dissipation of processing units with hybrid logarithmic approximation.\relax }}{68}{table.caption.54}%
\contentsline {table}{\numberline {3.9}{\ignorespaces Experimental results.\relax }}{70}{table.caption.57}%
\contentsline {table}{\numberline {3.10}{\ignorespaces Platform implementations.\relax }}{71}{table.caption.59}%
\addvspace {10\p@ }
\contentsline {xchapter}{Accelerating Convolutional Neural Networks: Hybrid 6-bit Floating-Point Precision}{73}{chapter.4}%
\contentsline {table}{\numberline {4.1}{\ignorespaces Resource utilization and power dissipation on the Zynq-7007S SoC.\relax }}{96}{table.caption.94}%
\contentsline {table}{\numberline {4.2}{\ignorespaces Compute performance of the CPU and TP on each Conv2D tensor operation. This table presents: tensor operation, computational cost in mega floating-point operations (MFLOP), latency, throughput, power efficiency, and estimated energy consumption as the energy delay product (EDP).\relax }}{97}{table.caption.95}%
\contentsline {table}{\numberline {4.3}{\ignorespaces Resource utilization and power dissipation of individual multiplier and adder floating-point (IEEE 754) operator cores (Xilinx LogiCORE IP).\relax }}{97}{table.caption.97}%
\contentsline {table}{\numberline {4.4}{\ignorespaces Comparison of hardware implementation with related work.\relax }}{101}{table.caption.106}%
\addvspace {10\p@ }
\contentsline {xchapter}{Conclusion and Outlook}{103}{chapter.5}%
\addvspace {10\p@ }
\contentsline {xchapter}{Appendix}{107}{appendix.A}%
