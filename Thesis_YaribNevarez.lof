\babel@toc {english}{}
\addvspace {10\p@ }
\contentsline {xchapter}{Introduction}{1}{chapter.1}%
\addvspace {10\p@ }
\contentsline {xchapter}{Background and Related Work}{15}{chapter.2}%
\contentsline {figure}{\numberline {2.1}{\ignorespaces \gls {sbs} network architecture for handwritten digit classification task.\relax }}{18}{figure.caption.22}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces \gls {sbs} \glspl {ip_sbs} as independent computational entities, (a) illustrates an input layer with a massive amount of \glspl {ip_sbs} operating as independent computational entities, (b) shows a hidden layer with an arbitrary amount of \glspl {ip_sbs} as independent computational entities, (c) exhibits a set of neurons grouped in an \gls {ip_sbs}.\relax }}{19}{figure.caption.25}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces (a) Performance classification of \gls {sbs} NN versus equivalent \gls {cnn}, and (b) example of the first pattern in the MNIST test data set with different amounts of positive additive uniformly distributed noise.\relax }}{20}{figure.caption.27}%
\contentsline {figure}{\numberline {2.4}{\ignorespaces Floating-point number representation.\relax }}{36}{figure.caption.44}%
\addvspace {10\p@ }
\contentsline {xchapter}{Acceleration with Hybrid 8-bit Floating-Point and 4-bit Logarithmic Computation}{49}{chapter.3}%
\contentsline {figure}{\numberline {3.1}{\ignorespaces Dot-product hardware module with (a) standard floating-point (IEEE 754) arithmetic, (b) hybrid custom floating-point approximation, and (c) hybrid logarithmic approximation.\relax }}{52}{figure.caption.57}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces System-level overview of the embedded software architecture.\relax }}{54}{figure.caption.58}%
\contentsline {figure}{\numberline {3.3}{\ignorespaces System-level hardware architecture with scalable number of heterogeneous \glspl {pu}: \emph {Spike}, \emph {Conv}, \emph {Pool}, and \emph {FC}\relax }}{55}{figure.caption.59}%
\contentsline {figure}{\numberline {3.4}{\ignorespaces The \emph {Conv} processing unit and its six stages: (a) receive \gls {ip_sbs} vector, (b) spike firing, (c) receive spike kernel, (d) update dynamics, (e) dispatch new \gls {ip_sbs} vector, (f) dispatch output spike matrix.\relax }}{57}{figure.caption.62}%
\contentsline {figure}{\numberline {3.5}{\ignorespaces Dot-product hardware module with standard floating-point (IEEE 754) computation, (a) exhibits the initiation interval of 10 clock cycles, (b) presents the iteration latency of 19 clock cycles, (c) shows the pairwise product block in dark-gray, and (d) illustrates the accumulation block in light-gray.\relax }}{59}{figure.caption.64}%
\contentsline {figure}{\numberline {3.6}{\ignorespaces Dot-product hardware module with hybrid custom floating-point approximation, (a) exhibits the initiation interval of 2 clock cycles, (b) presents the iteration latency of 13 clock cycles, (c) shows the pairwise product blocks in dark-gray, and (d) illustrates the accumulation blocks in light-gray.\relax }}{60}{figure.caption.66}%
\contentsline {figure}{\numberline {3.7}{\ignorespaces Dot-product hardware module with hybrid logarithmic approximation, (a) exhibits the initiation interval of 2 clock cycles, (b) presents the iteration latency of 9 clock cycles, (c) shows the pairwise product block in dark-gray, and (d) illustrates the accumulation blocks in light-gray.\relax }}{60}{figure.caption.67}%
\contentsline {figure}{\numberline {3.8}{\ignorespaces Computation on embedded CPU.\relax }}{63}{figure.caption.70}%
\contentsline {figure}{\numberline {3.9}{\ignorespaces System overview of the top-level architecture with 8 processing units.\relax }}{64}{figure.caption.72}%
\contentsline {figure}{\numberline {3.10}{\ignorespaces Performance of processing units with standard floating-point (IEEE 754) computation.\relax }}{65}{figure.caption.74}%
\contentsline {figure}{\numberline {3.11}{\ignorespaces Performance bottleneck of cyclic computation on processing units with standard floating-point (IEEE 754) arithmetic, (a) exhibits the starting of $t_{PU}$ of \emph {Conv2} on a previous computation cycle, (b) presents $t_{CPU}$ of \emph {Conv2} on the current computation cycle, (c) shows the CPU waiting time (in gray color) for \emph {Conv2} as a busy resource (awaiting for \emph {Conv2} interruption), and (d) illustrates the $t_{f}$ from the previous computation cycle, the starting of $t_{PU}$ on the current computation cycle (\emph {Conv2} interruption on completion, and start current computation cycle).\relax }}{65}{figure.caption.75}%
\contentsline {figure}{\numberline {3.12}{\ignorespaces Noise tolerance on hardware PU with standard floating-point (IEEE 754) computation (benchmark/reference), (a) exhibits accuracy degradation applying $50\%$ of noise amplitude, and (b) illustrates convergence of inference with $400$ spikes.\relax }}{68}{figure.caption.79}%
\contentsline {figure}{\numberline {3.13}{\ignorespaces $\qopname \relax o{log}_2$-histogram of each synaptic weight matrix showing the percentage of matrix elements with given integer exponent.\relax }}{69}{figure.caption.81}%
\contentsline {figure}{\numberline {3.14}{\ignorespaces Performance on processing units with hybrid custom floating-point approximation, (a) exhibits computation schedule, (b) presents cyclic computation schedule, and (c) shows the performance of \emph {Conv2} from a previous computation cycle during the preprocessing of \emph {H1\_CONV} on the current computation cycle without bottleneck.\relax }}{71}{figure.caption.85}%
\contentsline {figure}{\numberline {3.15}{\ignorespaces Noise tolerance on hardware PU with custom floating-point approximation, (a) exhibits accuracy degradation applying $50\%$ of noise amplitude, and (b) illustrates convergence of inference with $400$ spikes.\relax }}{72}{figure.caption.86}%
\contentsline {figure}{\numberline {3.16}{\ignorespaces Performance of processing units with hybrid logarithmic approximation, (a) exhibits computation schedule, and (b) illustrates cyclic computation schedule.\relax }}{73}{figure.caption.89}%
\contentsline {figure}{\numberline {3.17}{\ignorespaces Noise tolerance on hardware PU with hybrid logarithmic approximation, (a) exhibits accuracy degradation applying $40\%$ of noise amplitude, (b) illustrates convergence of inference with $600$ spikes.\relax }}{74}{figure.caption.91}%
\contentsline {figure}{\numberline {3.18}{\ignorespaces Power dissipation breakdown of platform implementations, (a) \cite {nevarez2020accelerator} architecture with homogeneous AUs using standard floating-point arithmetic (IEEE 754), (b) reference architecture with specialized heterogeneous PUs using standard floating-point arithmetic (IEEE 754), (c) proposed architecture with hybrid custom floating-point approximation, and (d) proposed architecture with hybrid logarithmic approximation.\relax }}{76}{figure.caption.96}%
\addvspace {10\p@ }
\contentsline {xchapter}{Low-Power Conv2D Tensor Accelerator: Hybrid 6-bit Floating-Point Computation}{79}{chapter.4}%
\contentsline {figure}{\numberline {4.1}{\ignorespaces The workflow of our approach on embedded FPGAs.\relax }}{81}{figure.caption.98}%
\contentsline {figure}{\numberline {4.2}{\ignorespaces Base embedded system architecture.\relax }}{83}{figure.caption.99}%
\contentsline {figure}{\numberline {4.3}{\ignorespaces High level hardware architecture of the proposed tensor processor.\relax }}{83}{figure.caption.100}%
\contentsline {figure}{\numberline {4.4}{\ignorespaces Dot-product hardware module with (a) standard floating-point and (b) Hybrid-Float6.\relax }}{85}{figure.caption.103}%
\contentsline {figure}{\numberline {4.5}{\ignorespaces (a) Dot-product hardware module with Hybrid-Float6 MAC, (b) bias accumulation, (c) activation and normalization to IEEE754.\relax }}{85}{figure.caption.104}%
\contentsline {figure}{\numberline {4.6}{\ignorespaces Hybrid-Float6 multiply-accumulate hardware design.\relax }}{86}{figure.caption.106}%
\contentsline {figure}{\numberline {4.7}{\ignorespaces Design parameters for on-chip memory buffers on the TP.\relax }}{87}{figure.caption.108}%
\contentsline {figure}{\numberline {4.8}{\ignorespaces High level embedded software architecture.\relax }}{93}{figure.caption.114}%
\contentsline {figure}{\numberline {4.9}{\ignorespaces Software flowchart.\relax }}{93}{figure.caption.115}%
\contentsline {figure}{\numberline {4.10}{\ignorespaces Experimental setup for sensor analytics on structural health monitoring, all lengths are in meters (m).\relax }}{95}{figure.caption.118}%
\contentsline {figure}{\numberline {4.11}{\ignorespaces Spectrograms of sensors $S_1, S_2$ converted to grayscale for pulses at $x =0.105$ m, $y = 0.109$ m with noise disturbance.\relax }}{97}{figure.caption.119}%
\contentsline {figure}{\numberline {4.12}{\ignorespaces CNN-regression model for sensor analytics.\relax }}{98}{figure.caption.121}%
\contentsline {figure}{\numberline {4.13}{\ignorespaces Training results.\relax }}{99}{figure.caption.123}%
\contentsline {figure}{\numberline {4.14}{\ignorespaces Performance of the model with different data representations.\relax }}{100}{figure.caption.124}%
\contentsline {figure}{\numberline {4.15}{\ignorespaces Inference acceleration and power reduction on the TP with floating-point and HF6 vs. CPU on the Zynq-7007S SoC.\relax }}{103}{figure.caption.133}%
\contentsline {figure}{\numberline {4.16}{\ignorespaces Run-time inference of TensorFlow Lite on the Zynq-7007S SoC. (a) CPU ARM Cortex-A9 at $\unit [666]{MHz}$, (b) cooperative CPU + TP with floating-point Xilinx LogiCORE IP at $\unit [200]{MHz}$, and (c) cooperative CPU + TP with Hybrid-Float6 at $\unit [200]{MHz}$.\relax }}{105}{figure.caption.136}%
\contentsline {figure}{\numberline {4.17}{\ignorespaces 2D error distribution of three CNN-regression models.\relax }}{106}{figure.caption.138}%
\contentsline {figure}{\numberline {4.18}{\ignorespaces Hardware resource utilization on the Zynq-7007S SoC.\relax }}{107}{figure.caption.140}%
\contentsline {figure}{\numberline {4.19}{\ignorespaces Estimated power dissipation on the Zynq-7007S SoC with PS at $\unit [666]{MHz}$ and PL at $\unit [200]{MHz}$.\relax }}{107}{figure.caption.141}%
\addvspace {10\p@ }
\contentsline {xchapter}{Conclusion and Outlook}{111}{chapter.5}%
\addvspace {10\p@ }
\contentsline {xchapter}{Appendix}{115}{appendix.A}%
\contentsline {figure}{\numberline {A.1}{\ignorespaces High level embedded software architecture.\relax }}{115}{figure.caption.144}%
\contentsline {figure}{\numberline {A.2}{\ignorespaces Software flowchart.\relax }}{116}{figure.caption.145}%
\contentsline {figure}{\numberline {A.3}{\ignorespaces Collaboration diagram of TensorFlow delegate classes.\relax }}{117}{figure.caption.147}%
\contentsline {figure}{\numberline {A.4}{\ignorespaces Sequence diagram of TensorFlow delegate initialization.\relax }}{118}{figure.caption.148}%
\contentsline {figure}{\numberline {A.5}{\ignorespaces Sequence diagram of TensorFlow delegate execution.\relax }}{119}{figure.caption.149}%
\contentsline {figure}{\numberline {A.6}{\ignorespaces Tensor Processor task execution. (a) Setup transaction. (b) Compute transaction.\relax }}{120}{figure.caption.150}%
\contentsline {figure}{\numberline {A.7}{\ignorespaces Setup transaction buffer stream.\relax }}{120}{figure.caption.151}%
