\babel@toc {english}{}
\addvspace {10\p@ }
\contentsline {xchapter}{Introduction}{1}{chapter.1}%
\addvspace {10\p@ }
\contentsline {xchapter}{Background and Related Work}{15}{chapter.2}%
\contentsline {figure}{\numberline {2.1}{\ignorespaces \gls {sbs} network architecture for handwritten digit classification task.\relax }}{19}{figure.caption.23}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces \gls {sbs} \glspl {ip_sbs} as independent computational entities, (a) illustrates an input layer with a massive amount of \glspl {ip_sbs} operating as independent computational entities, (b) shows a hidden layer with an arbitrary amount of \glspl {ip_sbs} as independent computational entities, (c) exhibits a set of neurons grouped in an \gls {ip_sbs}.\relax }}{20}{figure.caption.26}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces (a) Performance classification of \gls {sbs} NN versus equivalent \gls {cnn}, and (b) example of the first pattern in the MNIST test data set with different amounts of positive additive uniformly distributed noise.\relax }}{21}{figure.caption.28}%
\contentsline {figure}{\numberline {2.4}{\ignorespaces Floating-point number representation.\relax }}{37}{figure.caption.45}%
\contentsline {figure}{\numberline {2.5}{\ignorespaces (a) System architecture. (b) Processing element array.\relax }}{47}{figure.caption.60}%
\contentsline {figure}{\numberline {2.6}{\ignorespaces (a) System architecture. (b) Convolution accelerator.\relax }}{48}{figure.caption.62}%
\contentsline {figure}{\numberline {2.7}{\ignorespaces (a) System architecture. (b) Processing element.\relax }}{49}{figure.caption.64}%
\contentsline {figure}{\numberline {2.8}{\ignorespaces (a) System architecture. (b) Convolution engine.\relax }}{50}{figure.caption.66}%
\addvspace {10\p@ }
\contentsline {xchapter}{Acceleration with Hybrid 8-bit Floating-Point and 4-bit Logarithmic Computation}{53}{chapter.3}%
\contentsline {figure}{\numberline {3.1}{\ignorespaces Dot-product hardware module with (a) standard floating-point (IEEE 754) arithmetic, (b) hybrid custom floating-point approximation, and (c) hybrid logarithmic approximation.\relax }}{56}{figure.caption.68}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces System-level overview of the embedded software architecture.\relax }}{58}{figure.caption.69}%
\contentsline {figure}{\numberline {3.3}{\ignorespaces System-level hardware architecture with scalable number of heterogeneous \glspl {pu}: \emph {Spike}, \emph {Conv}, \emph {Pool}, and \emph {FC}\relax }}{59}{figure.caption.70}%
\contentsline {figure}{\numberline {3.4}{\ignorespaces The \emph {Conv} processing unit and its six stages: (a) receive \gls {ip_sbs} vector, (b) spike firing, (c) receive spike kernel, (d) update dynamics, (e) dispatch new \gls {ip_sbs} vector, (f) dispatch output spike matrix.\relax }}{61}{figure.caption.73}%
\contentsline {figure}{\numberline {3.5}{\ignorespaces Dot-product hardware module with standard floating-point (IEEE 754) computation, (a) exhibits the initiation interval of 10 clock cycles, (b) presents the iteration latency of 19 clock cycles, (c) shows the pairwise product block in dark-gray, and (d) illustrates the accumulation block in light-gray.\relax }}{63}{figure.caption.75}%
\contentsline {figure}{\numberline {3.6}{\ignorespaces Dot-product hardware module with hybrid custom floating-point approximation, (a) exhibits the initiation interval of 2 clock cycles, (b) presents the iteration latency of 13 clock cycles, (c) shows the pairwise product blocks in dark-gray, and (d) illustrates the accumulation blocks in light-gray.\relax }}{64}{figure.caption.77}%
\contentsline {figure}{\numberline {3.7}{\ignorespaces Dot-product hardware module with hybrid logarithmic approximation, (a) exhibits the initiation interval of 2 clock cycles, (b) presents the iteration latency of 9 clock cycles, (c) shows the pairwise product block in dark-gray, and (d) illustrates the accumulation blocks in light-gray.\relax }}{64}{figure.caption.78}%
\contentsline {figure}{\numberline {3.8}{\ignorespaces Computation on embedded CPU.\relax }}{67}{figure.caption.81}%
\contentsline {figure}{\numberline {3.9}{\ignorespaces System overview of the top-level architecture with 8 processing units.\relax }}{68}{figure.caption.83}%
\contentsline {figure}{\numberline {3.10}{\ignorespaces Performance of processing units with standard floating-point (IEEE 754) computation.\relax }}{69}{figure.caption.85}%
\contentsline {figure}{\numberline {3.11}{\ignorespaces Performance bottleneck of cyclic computation on processing units with standard floating-point (IEEE 754) arithmetic, (a) exhibits the starting of $t_{PU}$ of \emph {Conv2} on a previous computation cycle, (b) presents $t_{CPU}$ of \emph {Conv2} on the current computation cycle, (c) shows the CPU waiting time (in gray color) for \emph {Conv2} as a busy resource (awaiting for \emph {Conv2} interruption), and (d) illustrates the $t_{f}$ from the previous computation cycle, the starting of $t_{PU}$ on the current computation cycle (\emph {Conv2} interruption on completion, and start current computation cycle).\relax }}{69}{figure.caption.86}%
\contentsline {figure}{\numberline {3.12}{\ignorespaces Noise tolerance on hardware PU with standard floating-point (IEEE 754) computation (benchmark/reference), (a) exhibits accuracy degradation applying $50\%$ of noise amplitude, and (b) illustrates convergence of inference with $400$ spikes.\relax }}{72}{figure.caption.90}%
\contentsline {figure}{\numberline {3.13}{\ignorespaces $\qopname \relax o{log}_2$-histogram of each synaptic weight matrix showing the percentage of matrix elements with given integer exponent.\relax }}{73}{figure.caption.92}%
\contentsline {figure}{\numberline {3.14}{\ignorespaces Performance on processing units with hybrid custom floating-point approximation, (a) exhibits computation schedule, (b) presents cyclic computation schedule, and (c) shows the performance of \emph {Conv2} from a previous computation cycle during the preprocessing of \emph {H1\_CONV} on the current computation cycle without bottleneck.\relax }}{75}{figure.caption.96}%
\contentsline {figure}{\numberline {3.15}{\ignorespaces Noise tolerance on hardware PU with custom floating-point approximation, (a) exhibits accuracy degradation applying $50\%$ of noise amplitude, and (b) illustrates convergence of inference with $400$ spikes.\relax }}{76}{figure.caption.97}%
\contentsline {figure}{\numberline {3.16}{\ignorespaces Performance of processing units with hybrid logarithmic approximation, (a) exhibits computation schedule, and (b) illustrates cyclic computation schedule.\relax }}{77}{figure.caption.100}%
\contentsline {figure}{\numberline {3.17}{\ignorespaces Noise tolerance on hardware PU with hybrid logarithmic approximation, (a) exhibits accuracy degradation applying $40\%$ of noise amplitude, (b) illustrates convergence of inference with $600$ spikes.\relax }}{78}{figure.caption.102}%
\contentsline {figure}{\numberline {3.18}{\ignorespaces Power dissipation breakdown of platform implementations, (a) \cite {nevarez2020accelerator} architecture with homogeneous AUs using standard floating-point arithmetic (IEEE 754), (b) reference architecture with specialized heterogeneous PUs using standard floating-point arithmetic (IEEE 754), (c) proposed architecture with hybrid custom floating-point approximation, and (d) proposed architecture with hybrid logarithmic approximation.\relax }}{80}{figure.caption.107}%
\addvspace {10\p@ }
\contentsline {xchapter}{Low-Power Conv2D Tensor Accelerator: Hybrid 6-bit Floating-Point Computation}{83}{chapter.4}%
\contentsline {figure}{\numberline {4.1}{\ignorespaces The workflow of our approach on embedded FPGAs.\relax }}{85}{figure.caption.109}%
\contentsline {figure}{\numberline {4.2}{\ignorespaces Base embedded system architecture.\relax }}{87}{figure.caption.110}%
\contentsline {figure}{\numberline {4.3}{\ignorespaces High level hardware architecture of the proposed tensor processor.\relax }}{88}{figure.caption.111}%
\contentsline {figure}{\numberline {4.4}{\ignorespaces Setup transaction buffer stream.\relax }}{89}{figure.caption.113}%
\contentsline {figure}{\numberline {4.5}{\ignorespaces Tensor Processor task execution. (a) Depicts the configuration mode along with its corresponding setup buffer stream. (b) Illustrates the execution mode, showcasing concurrent input and output tensor buffer streams.\relax }}{89}{figure.caption.114}%
\contentsline {figure}{\numberline {4.6}{\ignorespaces Dot-product hardware module with (a) standard floating-point and (b) Hybrid-Float6.\relax }}{90}{figure.caption.116}%
\contentsline {figure}{\numberline {4.7}{\ignorespaces (a) Dot-product hardware module with Hybrid-Float6 MAC, (b) bias accumulation, (c) activation and normalization to IEEE754.\relax }}{91}{figure.caption.117}%
\contentsline {figure}{\numberline {4.8}{\ignorespaces Hybrid-Float6 multiply-accumulate hardware design.\relax }}{92}{figure.caption.119}%
\contentsline {figure}{\numberline {4.9}{\ignorespaces Design parameters for on-chip memory buffers on the TP.\relax }}{93}{figure.caption.121}%
\contentsline {figure}{\numberline {4.10}{\ignorespaces High level embedded software architecture.\relax }}{98}{figure.caption.127}%
\contentsline {figure}{\numberline {4.11}{\ignorespaces Software flowchart.\relax }}{98}{figure.caption.128}%
\contentsline {figure}{\numberline {4.12}{\ignorespaces Collaboration diagram of TensorFlow delegate classes.\relax }}{100}{figure.caption.133}%
\contentsline {figure}{\numberline {4.13}{\ignorespaces Sequence diagram of TensorFlow delegate initialization.\relax }}{101}{figure.caption.135}%
\contentsline {figure}{\numberline {4.14}{\ignorespaces Sequence diagram of TensorFlow delegate execution.\relax }}{102}{figure.caption.137}%
\contentsline {figure}{\numberline {4.15}{\ignorespaces Experimental setup for sensor analytics on structural health monitoring, all lengths are in meters (m).\relax }}{104}{figure.caption.140}%
\contentsline {figure}{\numberline {4.16}{\ignorespaces Spectrograms of sensors $S_1, S_2$ converted to grayscale for pulses at $x =0.105$ m, $y = 0.109$ m with noise disturbance.\relax }}{105}{figure.caption.141}%
\contentsline {figure}{\numberline {4.17}{\ignorespaces CNN-regression model for sensor analytics.\relax }}{106}{figure.caption.143}%
\contentsline {figure}{\numberline {4.18}{\ignorespaces Training results.\relax }}{107}{figure.caption.145}%
\contentsline {figure}{\numberline {4.19}{\ignorespaces Performance of the model with different data representations.\relax }}{108}{figure.caption.146}%
\contentsline {figure}{\numberline {4.20}{\ignorespaces Inference acceleration and power reduction on the TP with floating-point and HF6 vs. CPU on the Zynq-7007S SoC.\relax }}{112}{figure.caption.155}%
\contentsline {figure}{\numberline {4.21}{\ignorespaces Run-time inference of TensorFlow Lite on the Zynq-7007S SoC. (a) CPU ARM Cortex-A9 at $\unit [666]{MHz}$, (b) cooperative CPU + TP with floating-point Xilinx LogiCORE IP at $\unit [200]{MHz}$, and (c) cooperative CPU + TP with Hybrid-Float6 at $\unit [200]{MHz}$.\relax }}{114}{figure.caption.158}%
\contentsline {figure}{\numberline {4.22}{\ignorespaces 2D error distribution of three CNN-regression models.\relax }}{115}{figure.caption.160}%
\contentsline {figure}{\numberline {4.23}{\ignorespaces Hardware resource utilization on the Zynq-7007S SoC.\relax }}{116}{figure.caption.162}%
\contentsline {figure}{\numberline {4.24}{\ignorespaces Estimated power dissipation on the Zynq-7007S SoC with PS at $\unit [666]{MHz}$ and PL at $\unit [200]{MHz}$.\relax }}{116}{figure.caption.163}%
\addvspace {10\p@ }
\contentsline {xchapter}{Conclusion and Outlook}{119}{chapter.5}%
\addvspace {10\p@ }
\contentsline {xchapter}{Appendix}{123}{appendix.A}%
\contentsline {figure}{\numberline {A.1}{\ignorespaces Collaboration diagram of the \gls {tp} delegate and hardware drivers.\relax }}{124}{figure.caption.166}%
