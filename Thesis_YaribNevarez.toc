\@ifundefined {etoctocstyle}{\let \etoc@startlocaltoc \@gobble \let \etoc@settocdepth \@gobble \let \etoc@depthtag \@gobble \let \etoc@setlocaltop \@gobble }{}
\babel@toc {english}{}
\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}%
\contentsline {section}{\numberline {1.1}Preamble}{1}{section.1.1}%
\contentsline {subsection}{\numberline {1.1.1}AI/ML in Industry 4.0}{2}{subsection.1.1.1}%
\contentsline {subsubsection}{\nonumberline Industry 4.0}{2}{section*.4}%
\contentsline {subsubsection}{\nonumberline Internet-of-Things in Industry}{2}{section*.5}%
\contentsline {subsubsection}{\nonumberline Artificial Intelligence in Internet-of-Things}{3}{section*.6}%
\contentsline {subsection}{\numberline {1.1.2}Approximation in AI/ML}{3}{subsection.1.1.2}%
\contentsline {subsubsection}{\nonumberline Network Compression and Quantization}{3}{section*.7}%
\contentsline {subsubsection}{\nonumberline Error Tolerance in AI/ML Algorithms}{4}{section*.8}%
\contentsline {subsubsection}{\nonumberline Approximate Computing}{4}{section*.9}%
\contentsline {section}{\numberline {1.2}Problem Statement}{5}{section.1.2}%
\contentsline {subsection}{\numberline {1.2.1}Power Dissipation}{5}{subsection.1.2.1}%
\contentsline {subsection}{\numberline {1.2.2}Aggressive Quantization}{5}{subsection.1.2.2}%
\contentsline {subsection}{\numberline {1.2.3}Interoperability}{6}{subsection.1.2.3}%
\contentsline {section}{\numberline {1.3}Working Hypothesis}{6}{section.1.3}%
\contentsline {section}{\numberline {1.4}Research Objective}{7}{section.1.4}%
\contentsline {section}{\numberline {1.5}Scope}{8}{section.1.5}%
\contentsline {section}{\numberline {1.6}Contributions}{10}{section.1.6}%
\contentsline {subsection}{\numberline {1.6.1}Spike-by-Spike Neural Networks}{10}{subsection.1.6.1}%
\contentsline {subsection}{\numberline {1.6.2}Convolutional Neural Networks}{10}{subsection.1.6.2}%
\contentsline {section}{\numberline {1.7}Publications}{11}{section.1.7}%
\contentsline {section}{\numberline {1.8}Dissertation Outline}{12}{section.1.8}%
\contentsline {chapter}{\numberline {2}Background}{13}{chapter.2}%
\contentsline {section}{\numberline {2.1}Spike-by-Spike Neural Networks}{13}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1}Basic Network Overview}{14}{subsection.2.1.1}%
\contentsline {subsection}{\numberline {2.1.2}Computational Cost}{14}{subsection.2.1.2}%
\contentsline {subsection}{\numberline {2.1.3}Error Tolerance}{16}{subsection.2.1.3}%
\contentsline {section}{\numberline {2.2}Conv2D Tensor Operation}{17}{section.2.2}%
\contentsline {section}{\numberline {2.3}Floating-point Number Representation}{17}{section.2.3}%
\contentsline {chapter}{\numberline {3}Accelerating Spike-by-Spike Neural Networks}{19}{chapter.3}%
\contentsline {section}{\numberline {3.1}Introduction}{19}{section.3.1}%
\contentsline {section}{\numberline {3.2}Related Work}{23}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}Network Compression}{23}{subsection.3.2.1}%
\contentsline {subsection}{\numberline {3.2.2}Classical Approximate Computing}{24}{subsection.3.2.2}%
\contentsline {subsection}{\numberline {3.2.3}Spike-by-Spike Neural Networks Accelerators}{24}{subsection.3.2.3}%
\contentsline {section}{\numberline {3.3}System Design}{25}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}Hardware Architecture}{25}{subsection.3.3.1}%
\contentsline {subsection}{\numberline {3.3.2}Conv Processing Unit}{26}{subsection.3.3.2}%
\contentsline {subsubsection}{\nonumberline Configuration Mode}{26}{section*.21}%
\contentsline {subsubsection}{\nonumberline Computation Mode}{27}{section*.22}%
\contentsline {subsection}{\numberline {3.3.3}Dot-Product Hardware Module}{27}{subsection.3.3.3}%
\contentsline {subsubsection}{\nonumberline Dot-Product with Standard Floating-Point Computation}{29}{section*.24}%
\contentsline {subsubsection}{\nonumberline Dot-Product with Hybrid Custom Floating-Point and Logarithmic Approximation}{30}{section*.26}%
\contentsline {section}{\numberline {3.4}Experimental Results}{33}{section.3.4}%
\contentsline {subsection}{\numberline {3.4.1}Performance Benchmark}{34}{subsection.3.4.1}%
\contentsline {subsubsection}{\nonumberline Benchmark on Embedded CPU}{34}{section*.29}%
\contentsline {subsubsection}{\nonumberline Benchmark on Processing Units with Standard Floating-Point Computation}{34}{section*.32}%
\contentsline {subsubsection}{\nonumberline Benchmark on Noise Tolerance Plot}{38}{section*.39}%
\contentsline {subsection}{\numberline {3.4.2}Design Exploration with Hybrid Custom Floating-Point and Logarithmic Approximation}{39}{subsection.3.4.2}%
\contentsline {subsubsection}{\nonumberline Parameters for Numeric Representation of Synaptic Weight Matrix}{40}{section*.41}%
\contentsline {subsubsection}{\nonumberline Design Exploration for Dot-product with Hybrid Custom Floating-Point Approximation}{40}{section*.43}%
\contentsline {subsubsection}{\nonumberline Design Exploration for Dot-Product whit Hybrid Logarithmic Approximation}{42}{section*.48}%
\contentsline {subsection}{\numberline {3.4.3}Results and Discussion}{45}{subsection.3.4.3}%
\contentsline {section}{\numberline {3.5}Conclusions}{47}{section.3.5}%
\contentsline {chapter}{\numberline {4}Accelerating Convolutional Neural Networks}{49}{chapter.4}%
\contentsline {section}{\numberline {4.1}Introduction}{49}{section.4.1}%
\contentsline {section}{\numberline {4.2}Related work}{52}{section.4.2}%
\contentsline {subsection}{\numberline {4.2.1}Hybrid Custom Floating-Point}{52}{subsection.4.2.1}%
\contentsline {subsection}{\numberline {4.2.2}Low-Precision Floating-Point}{52}{subsection.4.2.2}%
\contentsline {subsection}{\numberline {4.2.3}Low-Power}{53}{subsection.4.2.3}%
\contentsline {section}{\numberline {4.3}System Design}{53}{section.4.3}%
\contentsline {subsection}{\numberline {4.3.1}Base embedded system architecture}{53}{subsection.4.3.1}%
\contentsline {subsection}{\numberline {4.3.2}Tensor processor}{54}{subsection.4.3.2}%
\contentsline {subsubsection}{\nonumberline Modes of operation}{54}{section*.61}%
\contentsline {subsubsection}{\nonumberline Dot-product with hybrid floating-point}{55}{section*.62}%
\contentsline {subsubsection}{\nonumberline Multiply-Accumulate}{55}{section*.65}%
\contentsline {subsubsection}{\nonumberline On-chip memory utilization}{58}{section*.67}%
\contentsline {subsection}{\numberline {4.3.3}Training Method}{59}{subsection.4.3.3}%
\contentsline {subsubsection}{\nonumberline Training with Iterative Early Stop}{59}{section*.69}%
\contentsline {subsubsection}{\nonumberline Quantization-Aware Training}{60}{section*.70}%
\contentsline {subsection}{\numberline {4.3.4}Embedded software architecture}{60}{subsection.4.3.4}%
\contentsline {section}{\numberline {4.4}Experimental Results}{62}{section.4.4}%
\contentsline {subsection}{\numberline {4.4.1}Sensor Analytics Application}{62}{subsection.4.4.1}%
\contentsline {subsubsection}{\nonumberline Experimental Setup}{63}{section*.76}%
\contentsline {subsubsection}{\nonumberline Data Sets}{64}{section*.77}%
\contentsline {subsubsection}{\nonumberline CNN-Regression Model}{66}{section*.80}%
\contentsline {subsection}{\numberline {4.4.2}Training}{67}{subsection.4.4.2}%
\contentsline {subsubsection}{\nonumberline Base Model}{67}{section*.82}%
\contentsline {subsubsection}{\nonumberline TensorFlow Lite 8-bit Quantization}{68}{section*.85}%
\contentsline {subsubsection}{\nonumberline Inference of non-quantized models on HF6 hardware}{70}{section*.86}%
\contentsline {subsubsection}{\nonumberline Quantization-Aware Training for HF6 hardware}{70}{section*.87}%
\contentsline {subsubsection}{\nonumberline Quantization-Aware Training for Hybrid-Logarithmic 6-bit}{70}{section*.88}%
\contentsline {subsection}{\numberline {4.4.3}Hardware Design Exploration}{70}{subsection.4.4.3}%
\contentsline {subsubsection}{\nonumberline Benchmark on Embedded CPU}{71}{section*.89}%
\contentsline {subsubsection}{\nonumberline Benchmark on Tensor Processor Synthesized with Xilinx LogiCORE IP for Floating-Point Computation}{71}{section*.90}%
\contentsline {subsubsection}{\nonumberline Tensor Processor Synthesized with Hybrid-Float6 Hardware Architecture}{72}{section*.95}%
\contentsline {subsection}{\numberline {4.4.4}Discussion}{75}{subsection.4.4.4}%
\contentsline {subsubsection}{\nonumberline Training and Quantization}{75}{section*.97}%
\contentsline {subsubsection}{\nonumberline Implementation and Performance}{75}{section*.99}%
\contentsline {subsubsection}{\nonumberline SoC Design and Compatibility}{77}{section*.102}%
\contentsline {section}{\numberline {4.5}Conclusions}{77}{section.4.5}%
\contentsline {chapter}{\numberline {5}Conclusion and Outlook}{79}{chapter.5}%
\contentsline {section}{\numberline {5.1}Conclusion}{79}{section.5.1}%
\contentsline {section}{\numberline {5.2}Outlook}{80}{section.5.2}%
\contentsline {section}{\numberline {5.3}Summary}{81}{section.5.3}%
\contentsline {chapter}{\numberline {A}Appendix}{83}{appendix.A}%
\contentsline {section}{\numberline {A.1}SbS algorithm}{83}{section.A.1}%
