\chapter{Introduction}\label{chap.intro}
\minitoc
\section{Preamble}

This section presents the preamble to investigate design methodologies for low-power hardware accelerators of \gls{ai}/\gls{ml} algorithms focusing on inference quality, scalability, versatility, and compatibility as design philosophy.

\subsection{AI/ML in Industry 4.0}
\gls{ai} and \gls{ml} play a crucial role in the context of Industry 4.0, which is characterized by the integration of digital technologies into manufacturing and industrial processes to create a more connected, intelligent, and automated environment.

\subsubsection{Industry 4.0}
Since the beginning of industrialization, technological leaps have led to paradigm shifts, now called "industrial revolutions": from mechanization, electrification, and later, digitalization (the so-called 3rd industrial revolution). Based on the advanced digitalization within factories, the combination of Internet technologies and future-oriented technologies in the field of "smart" things (machines and products) seems to result in a new fundamental paradigm shift in industrial production. Emerging from this future expectation, the term "Industry 4.0" was established for an expected "4th industrial revolution"~\cite{lasi2014industry}.


\subsubsection{Internet-of-Things in Industry}
% Context background
To build the emerging environment of Industry 4.0, disruptive technologies are required to handle autonomous communications between all industrial embedded computers throughout the factory and the Internet. Such technologies offer the potential to transform the industry along the entire production chain and stimulate productivity and overall economic growth \cite{espinoza2020estimating}. These technologies include cloud computing, big data, and specially a new generation of \gls{iot} devices fused with \gls{cps}, safety-security, augmented reality, \gls{ml}, and hardware accelerators~\cite{alcacer2019scanning}.

\subsection{Rationale for \gls{ai}/\gls{ml} Acceleration in \gls{iot} Applications}
% Particular background
The continuous evolution of \gls{ai} algorithms and \gls{iot} devices has not only made \gls{ai} the major workload running on these embedded devices, but has transformed \gls{ai} into the main approach for industrial solutions, especially in the rise of Industry 4.0~\cite{alcacer2019scanning}. As a result, the term of \gls{iot} has also been redefined as \gls{ai} of Things (AIoT) to emphasize the impact on this technology~\cite{zhang2020empowering}.

There are key motivations for accelerating \gls{ai}/\gls{ml} algorithms within \gls{iot} devices, focusing on mission criticality, real-time processing, data privacy and security, and offline operation capabilities~\cite{loh20201}:

\subsubsection{Mission Criticality}
In mission-critical applications such as medical devices, autonomous vehicles, and industrial automation, the need for quick and reliable decisions is essential. Low-power neural network accelerators allow these devices to make decisions in real time without significant power consumption. These accelerators can be designed to meet stringent safety and reliability standards, reducing the risk of failures in critical applications.

\subsubsection{Real-Time Processing}
For applications such as autonomous vehicles, drones, and robotics, immediate processing of sensor data (such as images and LIDAR data) is necessary. Low-power accelerators can process this data on-device in real time, reducing latency compared to cloud-based solutions. Real-time processing is crucial for responsive and adaptive system behavior, which is essential for the smooth functioning of \gls{iot} systems.

\subsubsection{Data Privacy and Security}
Processing data on-device, rather than sending it to a central server or cloud, can substantially mitigate the risk of data interception or tampering. With the increasing scrutiny and regulations around data privacy (e.g., \gls{gdpr}), processing data locally on a device is a critical advantage, enabling compliance with data protection laws. For sensitive applications such as smart home devices or wearables that handle personal data, on-device processing with low-power neural network accelerators maintains user privacy.

\subsubsection{Offline Operation Capabilities}
Low-power neural network accelerators enable IoT and embedded devices to operate independently of network connectivity, allowing for effective functioning in remote or disconnected environments. These accelerators allow for continuous operation without reliance on a central server, which is critical in situations where connectivity is inconsistent, costly, or non-existent, such as in agricultural or maritime contexts.

\subsubsection{Energy Efficiency}
For battery-powered or energy-harvesting devices, the power consumption of the processing unit is a critical constraint. Low-power accelerators are optimized for energy efficiency, which is essential for prolonging device operational lifetime without frequent battery replacements or recharging.

\subsubsection{Emerging Applications}
\begin{itemize}
	\item \textbf{Edge AI:} This is where \gls{ai} algorithms are processed locally on a hardware device. The algorithms are run locally, on a hardware chip, without requiring a connection to a network, unlike in cloud \gls{ai} where algorithms run in a data center. Low-power accelerators are key enablers of this paradigm.
	\item \textbf{TinyML:} \gls{tinyml} is the deployment of machine learning algorithms on low-power hardware, such as microcontrollers. These devices are particularly relevant in \gls{iot} applications where power, cost, and form factor are key considerations.
	\item \textbf{Predictive Maintenance:} In industrial \gls{iot} applications, low-power neural network accelerators can be used to continuously monitor the health of machinery and predict when maintenance is required in a reliable and energy efficient manner.
	\item \textbf{Health Monitoring:} Continuous health and wellness monitoring through wearable devices is an emerging application. For example, real-time analysis of ECG or other biometric data can be performed efficiently on-device using low-power accelerators.
	\item \textbf{Smart Agriculture:} These devices can be used for precision farming, where they analyze data from various sensors in real time and make decisions to optimize farming practices.
	\item \textbf{Natural Language Processing:} In consumer devices, such as smart speakers or smartphones, low-power neural network accelerators enable more efficient and responsive voice recognition and processing.
	\item \textbf{Federated Learning:} Low-power accelerators can facilitate \gls{fl} by efficiently handling the computations required for local model training and updates, thereby contributing to both data privacy and security.
\end{itemize}



\subsection{Approximation in AI/ML}
Based on the error tolerance in \gls{ml} algorithms, a promising solution is approximate computing. This paradigm has been used in a wide range of applications to increase hardware efficiency~\cite{han2013approximate}. For neural network applications, two main approximation strategies are used, namely network compression and classical approximate computing~\cite{bouvier2019spiking}.

\subsubsection{Network Compression and Quantization}
Researchers focusing on embedded applications started lowering the precision of weights and activation maps to shrink the memory footprint of the large number of parameters representing \glspl{ann}, a method known as network quantization. In this manner, reduced bit precision causes a small accuracy loss~\cite{courbariaux2015binaryconnect, han2015deep, hubara2017quantized, rastegari2016xnor}. In addition to quantization, network pruning reduces the model size by removing structural portions of the parameters and its associated computations~\cite{lecun1989optimal,hassibi1992second}. This method has been identified as an effective technique to improve the efficiency of neural network models for applications with limited computational and energy budget~\cite{molchanov2016pruning,li2016pruning, liu2018rethinking}. These techniques leverage the intrinsic error-tolerance of neural networks, as well as their ability to recover from accuracy degradation while training.

\subsubsection{Error Tolerance in AI/ML Algorithms}
An algorithm can be regarded as error-tolerant or error-resilient when it provides a result with the required accuracy while utilizing processing components with a certain degree of inaccuracy. There are several reasons why an algorithm/application is tolerant of errors as discussed in~\cite{chippa2013analysis}. These include noisy or redundant data of the algorithm, approximate or probabilistic computations within the algorithm, and a range of acceptable outcomes. This is the case of \gls{ai}/\gls{ml} models.


\subsubsection{Approximate Computing}
%Geneal background
Approximate computing is a design paradigm that is able to tradeoff computation quality (e.g., accuracy) and computational efficiency (e.g., in run-time, chip-area, and/or energy) by exploiting the error resilience of applications/algorithms~\cite{gillani2020exploiting, zhang2015approxann}. Data redundancy of neural networks incorporate a certain degree of resilience against random external and internal perturbations;
for instance, noisy inputs and random hardware errors. This property can be exploited in a cross-layer resilience approach~\cite{carter2010design}: by leveraging error tolerance at algorithmic-level, it can be allowed a certain degree of inaccuracies at the computing-level. This approach consists of designing processing elements that approximate their computation by employing cleverly modified algorithmic logic units~\cite{han2013approximate}.

Approximate computing techniques allow substantial enhancement in processing efficiency with moderated accuracy degradation. Some research papers have shown the feasibility of applying approximate computing to the inference stage of neural networks~\cite{lotrivc2012applicability, han2013approximate, du2014leveraging, mrazek2016design, sarwar2016multiplier, zervakis2021approximate}. Such techniques usually demonstrated small inference accuracy degradation, but significant enhancement in computational performance, chip-area, and energy consumption. Hence, by taking advantage of the intrinsic error-tolerance of neural networks, approximate computing is positioned as a promising approach for \gls{ai}/\gls{ml} computation on resource-limited devices.

% Problem to solve
\section{Problem Statement}
A fundamental problem for the rise of \gls{ai} in Industry 4.0 is the fact that \gls{ml} models, are highly computational and data intensive. This brings significant challenges across the spectrum of computing hardware, specially in the scope of embedded systems~\cite{venkataramani2016efficient}. The most deployed models and also some of the most computationally and energy expensive are for computer vision using \glspl{cnn}. Compared to the conventional image processing methods, the accuracy of \gls{cnn} has improved significantly that by 2015, a human can no longer beat a computer in image classification~\cite{loh20201}. The early development of \glspl{cnn} before 2016 mainly focused on accuracy enhancement without considering computational costs. While accuracy of deep \gls{cnn} for image classification improved 24\% between 2012 and 2016, the demand on hardware resources increased more than $10\times$. Starting from 2017, significant attention was paid to improve hardware efficiency in terms of compute power, memory bandwidth, and power consumption, while maintaining accuracy at a similar level to human perception~\cite{venkataramani2016efficient}.

\subsection{Power Dissipation}
Consequently, the recent breakthroughs in \gls{ai}/\gls{ml} applications have brought significant advancements in neural network processors~\cite{jouppi2017datacenter}. To bring the inference speed to an acceptable level, \gls{asic} with \gls{npu} are becoming ubiquitous in both embedded and general purpose computing. \glspl{npu} perform several tera operations per second in a confined area, as a consequence, they become subject to elevated on-chip power densities that rapidly result in excessive on-chip temperatures during operation~\cite{amrouch2020npu}. Subsequently, the elevated power supply, physical dimensions, heat sink and air cooling requirements demand a balance between the benefits of \gls{ml} against its financial and environmental costs. This outcome is delivered by parallel computing techniques, yet unsustainable in resource-constrained devices.
Therefore, radical changes to conventional computing are required in order to sustain and improve performance while satisfying energy and temperature constraints~\cite{gillani2020exploiting}.

\subsection{Aggressive Quantization}
Furthermore, reducing the compute hardware with aggressive quantization such as binary \cite{courbariaux2015binaryconnect}, ternary \cite{lin2015neural}, and mixed precision (2-bit activations and ternary weights) \cite{colangelo2018exploration} typically incur significant accuracy degradation for very low precisions, especially for complex problems~\cite{faraone2019addnet}, such as: regression, semantic segmentation, machine translation, language generation, playing agents, image/music generation, and medical applications.

While aggressive quantization can be beneficial for resource-constrained environments and non-critical applications, careful consideration and a more conservative approach are essential for ensuring the safety and reliability of \gls{ai}/\gls{ml} systems in high-accuracy or mission-critical domains. Quantization techniques must be chosen wisely, keeping in mind the specific requirements and constraints of each application.

\subsection{Interoperability}
Aggressive or exotic quantization might not be supported by all hardware/software platforms. Custom hardware accelerators may have limitations on the precision they can handle effectively, limiting the compatibility and portability of aggressively quantized models. Aggressively quantized models may not be compatible with all frameworks, libraries, or \gls{ai} platforms, limiting their interoperability and portability across different environments. In real-world deployment scenarios, there may be constraints and requirements that make aggressive quantization impractical, especially when high-accuracy, compatibility, portability, and interoperability are necessary.
%%%%%%%%%%%%%%
\section{Working Hypothesis}

\textit{The development of design methodologies for custom low-power neural network accelerators, utilizing a \gls{fp} mixed or hybrid precision approach with reduced bit-width for weights and biases and standard \gls{fp} activation maps, can achieve substantial reductions in power consumption and thermal dissipation without significant accuracy degradation. This accelerator design is expected to enable efficient hardware operation, ensure broad compatibility and interoperability across varying hardware and software platforms, maintaining accuracy through \gls{qat} methods.}

\paragraph{Reduced Precision Requirement for Weights and Biases}
\begin{itemize}
	\item H1: Utilizing lower precision for weights and biases in neural network models will significantly reduce the memory requirements and computational complexity of the accelerator, without causing substantial decrease in model accuracy~\cite{lai2017deep}.
\end{itemize}

\paragraph{Floating-Point Activation Maps}
\begin{itemize}
	\item H2: Retaining higher precision in activation maps in the custom accelerator will prevent significant accuracy degradation during inference, despite the reduced precision of weights and biases.
\end{itemize}

\paragraph{Hardware Efficiency}
\begin{itemize}
	\item H3: The hybrid precision approach, which combines standard \gls{fp} activation maps and reduced bit-width for weights and biases, is expected to improve the hardware efficiency of the neural network accelerator. This approach is hypothesized to enable faster arithmetic operations and reduce memory bandwidth requirements~\cite{lai2017deep}.
\end{itemize}

\paragraph{Compatibility and Interoperability}
\begin{itemize}
	\item H4: The custom low-power neural network accelerator is hypothesized to be designed to efficiently handle different \gls{fp} formats or precision levels for weights, biases, and activation maps; therefore, ensuring compatibility and interoperability across various software frameworks and hardware platforms.
\end{itemize}

\paragraph{Quantization-Aware Training}
\begin{itemize}
	\item H5: Implementing \gls{qat} in the training process will help the neural network model adapt to the hybrid precision representation used in the accelerator, ensuring that the reduced precision for weights and biases does not cause significant accuracy loss.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Research Objective}
Develop advanced methodologies for energy-efficient neural network accelerators with custom \gls{fp} computation in resource-constrained environments. This research objective encompasses several key aspects that are crucial for the progress of energy-efficient neural network accelerators with custom \gls{fp} computation:

\begin{itemize}
	\item \textbf{Optimized Custom \gls{fp} Representation}. Examine innovative custom \gls{fp} representation tailored for neural network computations. This includes the study of various bit-widths, exponent formats, and non-standard \gls{fp} representations.
	\item \textbf{Energy-Efficient Design Strategies}. Investigate design strategies at various levels, from logic-level optimizations to architectural-level approaches, aiming to achieve minimal energy consumption.
	\item \textbf{Custom \gls{fp} Arithmetic Units}. Research the design and implementation of arithmetic units that efficiently conduct the proposed custom \gls{fp} computations, with a focus on energy-saving during arithmetic operations.
	\item \textbf{Task-Specific Neural Network Optimization}. Examine accelerator architectures designed particularly for neural network tasks in environments with limited resources. Techniques such as pipe-lining, data quantization, and hardware-specific optimizations are considered to maintain efficiency and \gls{qor}.
	\item \textbf{Precision and Quantization Impact Analysis}. Explore and present a thorough analysis of the impacts of quantization and reduced precision on model accuracy, utilizing \gls{qat} and dynamic precision techniques to preserve or improve accuracy.
	\item \textbf{Scalability and Flexibility}. Investigate scalability methods for handling diverse neural network models and sizes effectively.
	\item \textbf{Comparative Analysis with Alternative Techniques}. Feature comparisons with other energy-efficient neural network accelerators to highlight the distinctiveness and strengths of the proposed custom \gls{fp} computation approaches.
	\item \textbf{Performance Evaluation and Benchmarking}. Conduct evaluation and benchmarking against the existing state-of-the-art, with the goal to display benefits in terms of energy efficiency and computational performance.
	\item \textbf{Practical Application Demonstrations}. This objective encompasses demonstrating the practical applicability in actual energy-efficient and resource-constrained scenarios, such as IoT devices.
	\item \textbf{Directions for Future Research}. This dissertation is aimed at contributing valuable perspectives on future research trajectories for further refining energy-efficient neural network accelerators with custom \gls{fp} computation, potential integration with edge devices, and the implications on the wider domain of machine learning hardware.
\end{itemize}

The overall research objective is set to tackle significant challenges in crafting efficient hardware accelerators for neural networks, emphasizing the reduction of energy consumption through custom \gls{fp} computation and enhancing the state-of-the-art in energy-efficient neural network accelerators.



\section{Scope}\label{chap1.scope}
The scope of this research revolves around enabling energy-efficient and high-quality inference of \gls{sbs} and \gls{cnn} models on resource-constrained applications. This scope presents hardware design methodologies specifically tailored for \gls{sbs} and \gls{cnn} models on \gls{soc} devices with limited computational resources, memory, and power constraints.



\begin{itemize}

\item \textbf{Spike-by-Spike Neural Networks}. \glspl{snn} offer advantageous robustness and the potential to achieve a power efficiency closer to that of the human brain. \glspl{snn} operate reliably using stochastic elements that are inherently non-reliable mechanisms~\cite{mcdonnell2011benefits}. This provides superior resistance against adversary attacks~\cite{ernst2007efficient, Dapello2020.06.16.154542}. Beside robustness, \glspl{snn} have further advantages like the possibility of a more efficient asynchronous parallelization and higher energy efficiency than conventional \glspl{ann}.

The Spike-by-Spike model is on the less realistic side of the \gls{snn} scale of biological realism~\cite{rotermund2019Backpropagation,ernst2007efficient}. Consequently, the hardware complexity of \gls{sbs} network implementations is greatly reduced~\cite{rotermund2018massively}. In spite of this, \gls{sbs} still uses stochastic spikes as a means of transmitting information between populations of neurons and thus retains the advantageous robustness of \glspl{snn}. A significant research effort has been done in \gls{snn} accelerators, see e.g.~\cite{roy2019towards,bouvier2019spiking,
	young2019review,TrueNorth_Trans15,Spinnaker_Trans13,davies2018loihi}.

However, hardware accelerators that focus on \gls{sbs} have only been partially investigated so far~\cite{rotermund2018massively}. Enhanced \gls{sbs} accelerators will have a double impact. From scientific and application point of view, they will facilitate fundamental research for neuroscience~\cite{ernst2007efficient,rotermund2019recurrentsbs, dayan2001theoretical} and contribute to the deployment of robust neural networks in small embedded systems~\cite{nevarez2020accelerator}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item \textbf{Convolutional Neural Networks}. \glspl{cnn} represent the essential building blocks in 2D pattern analytics. Sensor-based applications such as mechanical fault detection \cite{li2019sensor,dong2018rolling}, structural health monitoring \cite{nagayama2007structural}, \gls{har} \cite{wang2019deep}, hazardous gas detection \cite{kim2017hazardous} have been powered by \gls{cnn} models in industry and academia. \gls{cnn} models provide advantages such as local dependency, scale invariance, and noise resilience in analytics \cite{du2014leveraging}. However, these models are computationally intensive and power-hungry. This is particularly challenging for low-power embedded applications, specially in the field of \gls{iot}. As a result, numerous commercial \gls{asic} and \gls{fpga} accelerators have been proposed, these are targeting both \gls{hpc} for data-centers and embedded systems applications.

However, most accelerators have been implemented to target mid- to high-range \glspl{fpga} for computationally intensive \gls{cnn} models such as AlexNet, VGG-16, and ResNet-18. The main drawbacks of these implementations are power supply demands, physical dimensions, heat sink requirements, air cooling, and a resulting high price. In some cases, these implementations are not feasible for ubiquitous low-power/resource-constrained applications. Furthermore, reducing the compute hardware with aggressive quantization such as binary \cite{courbariaux2015binaryconnect}, ternary \cite{lin2015neural}, and mixed precision (2-bit activations and ternary weights) \cite{colangelo2018exploration} typically incur significant accuracy degradation for very low precisions, especially for complex problems~\cite{faraone2019addnet}.

\end{itemize}

\section{Contributions}
This research produces hardware design methodologies for low-power hardware accelerators with custom \gls{fp} computation that reconcile efficiency with inference quality, and compatibility. This work is demonstrated on \gls{sbs} and \gls{cnn} hardware accelerators on resource-constrained \gls{soc} \glspl{fpga}:

\subsection{Accelerating Spike-by-Spike Neural Networks with Hybrid 8-bit Floating-Point and 4-bit Logarithmic Computation}
\begin{enumerate}
	\item An optimized \gls{fp} \gls{mac} design with hybrid precision is presented. This design utilizes the IEEE 754 single-precision \gls{fp} for feature maps and custom \gls{fp} representation for weights. The custom \gls{fp} precision does not implement a sign bit and has reduced exponent and mantissa bit widths. This design accumulates values in a denormalized manner and produces IEEE 754 single-precision results.This design not only upholds \gls{qor} but also enhances efficiency through reduced latency, diminished power dissipation, minimized hardware resources, and a smaller memory footprint.
	\item A design exploration is presented focusing on input weight \gls{fp} representation of 8 and 4-bit. Evaluation is reported across various facets such as run-time, accuracy degradation, hardware resource utilization, and power consumption. An embedded system architecture is presented to assess the performance of the custom \gls{fp} \gls{mac}. In evaluations using a generative model based on \gls{nnmf} (\gls{sbs} model), a notable latency improvement of $20.5\times$ was measured in comparison to an embedded \gls{cpu} (ARM Cortex-A9 operating at \unit[666]{MHz}). Notably, in a handwritten digit recognition task, an accuracy degradation of less than $0.5\%$ was measured.
	\item A noise tolerance plot is proposed as a quality monitor, which is intended to serve as an intuitive visual model. This model offers insights into the accuracy degradation of \gls{nnmf} models (\gls{sbs} networks) when subjected to custom \gls{fp} computation.
	\item The design presented for custom \gls{fp} \gls{mac} is considered adaptable for use as a building block in other error-resilient applications, such as image/video processing.
\end{enumerate}


\subsection{Accelerating Convolutional Neural Networks with Hybrid 6-bit Floating-Point Computation}
\begin{enumerate}
	\item A 6-bit \gls{fp} representation for weights is presented as \gls{hf6} quantization. An optimized hardware \gls{mac} is proposed, wherein mantissa multiplication is reduced to a multiplexer-adder operation. The intrinsic error tolerance of \gls{ann} is harnessed in this method to further refine the hardware design via approximation. To maintain model accuracy, a \gls{qat} approach is introduced. Notably, in certain instances, this method elevates accuracy, attributed to the regularization effect.
	
	\item A custom hardware/software co-design framework for \gls{cnn} sensor analytics applications has been developed, targeting resource-constrained \gls{soc} \glspl{fpga}. This architecture incorporates TensorFlow Lite.
	
	\item A customizable \gls{tp} is presented as a proof of concept demonstration with \gls{hf6}. In this design, accelerations of up to 48X are achieved by the \emph{Conv2D} tensor operation in comparison to the \gls{cpu} running TensorFlow Lite. This enhancement is realized without accuracy degradation employing \gls{qat}.
	
	\item The potential of this approach is demonstrated with a \gls{cnn}-regression model for anomaly localization in \gls{shm} based on \gls{ae}. A hardware design exploration is addressed evaluating accuracy, compute performance, hardware resource utilization, and energy consumption.
\end{enumerate}

\section{Publications}
The outcome of this dissertation, including the collaborative works with our research partners is a list of publications including \cite{nevarez2020accelerator, nevarez2021accelerating, yn2022cnnsensor}. In the following, a complete list of the related publications are itemized.

\begin{enumerate}
	
	\subsubsection*{Journal Articles}
	
	\item \textbf{Yarib Nevarez}, David Rotermund, Klaus R Pawelzik, and Alberto Garcia-Ortiz, "Accelerating Spike-by-Spike Neural Networks on FPGA With Hybrid Custom Floating-Point and Logarithmic Dot-Product Approximation," 
	\newblock IEEE Access, vol. 9, pp. 80603--80620, May 2021, doi: 10.1109/ACCESS.2021.3085216.  
	
	\item \textbf{Yarib Nevarez}, Andreas Beering, Amir Najafi, Ardalan Najafi, Wanli Yu, Yizhi Chen, Karl-Ludwig Krieger, and Alberto Garcia-Ortiz, "CNN Sensor Analytics With Hybrid-Float6 Quantization on Low-Power Embedded FPGAs," 
	\newblock IEEE Access, vol. 11, pp. 4852--4868, January 2023, doi: 10.1109/ACCESS.2023.3235866.

	
	\subsubsection*{Conference Proceedings}
	
	\item \textbf{Yarib Nevarez}, Alberto Garcia-Ortiz, David Rotermund, and Klaus R Pawelzik, "Accelerator framework of spike-by-spike neural networks for inference and incremental learning in embedded systems,"
	\newblock 2020 9th International Conference on Modern Circuits and Systems Technologies (MOCAST), Bremen, 2020, pp. 1--5, doi: 10.1109/MOCAST49295.2020.9200288.
	
	\item Wanli Yu, Ardalan Najafi, \textbf{Yarib Nevarez}, Yanqiu Huang and Alberto Garcia-Ortiz, "TAAC: Task Allocation Meets Approximate Computing for Internet of Things," 
	\newblock 2020 IEEE International Symposium on Circuits and Systems (ISCAS), Sevilla, 2020, pp. 1-5, doi: 10.1109/ISCAS45731.2020.9180895.
	
	\item Amir Najafi, Ardalan Najafi, \textbf{Yarib Nevarez} and Alberto Garcia-Ortiz, "Learning-Based On-Chip Parallel Interconnect Delay Estimation," 
	\newblock 2022 11th International Conference on Modern Circuits and Systems Technologies (MOCAST), Bremen, 2022, pp. 1--5, doi: 10.1109/MOCAST49295.2020.9200288.
	
	\item Yizhi Chen, \textbf{Yarib Nevarez}, Zhonghai Lu, and Alberto Garcia-Ortiz, "Accelerating Non-Negative Matrix Factorization on Embedded FPGA with Hybrid Logarithmic Dot-Product Approximation," 
	\newblock 2022 IEEE 15th International Symposium on Embedded Multicore/Many-core Systems-on-Chip (MCSoC), Malaysia, 2022, pp. 239--246, doi: 10.1109/MCSoC57363.2022.00070.
	
	\item Ardalan Najafi, Wanli Yu, \textbf{Yarib Nevarez}, Amir Najafi, Andreas Beering, Karl-Ludwig Krieger, and Alberto Garcia-Ortiz, "Acoustic Emission Source Localization using Approximate Discrete Wavelet Transform," \newblock 2023 12th International Conference on Modern Circuits and Systems Technologies (MOCAST), Bremen, 2023, pp. 1--5, doi: 10.1109/MOCAST57943.2023.10176952.
	
\end{enumerate}

\section{Dissertation Outline}

This dissertation is organized in three main parts: an introduction, where
the state of the art and related background are stated; a central core, where the proposed design methodologies and validation are presented; and a final part with the conclusion. More precisely:

\begin{enumerate}[I]
	\item \textbf{Introduction}: Chapter~\ref{chap.background} introduces the background related to \gls{sbs}, \gls{cnn}, and \gls{fp} number representation.
	\item \textbf{Core}: the proposed hardware design methodologies for \gls{sbs} and \gls{cnn} accelerators are presented in Chapter~\ref{chap.sbs} and Chapter~\ref{chap.cnn}, respectively.
	\item \textbf{Conclusions}: the final conclusions are presented in Chapter~\ref{chap.conclusion}.
\end{enumerate}