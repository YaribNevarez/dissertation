\chapter{Introduction}\label{chap.intro}
\minitoc
\section{Preamble}
The use of \gls{ai}/\gls{ml} is entering a new era with ubiquitous connected devices to enhance intelligence, functionality, and connectivity in our increasingly digital world. However, \gls{ai}/\gls{ml} algorithms are computationally and energy intensive, this represents an important challenge for sustainability and realization. Therefore, this digital transformation requires hardware design methodologies that reconcile efficiency with inference quality, and adaptability.

Hardware acceleration for embedded devices is expected to drive further advancements in \gls{ai}/\gls{ml} technologies, paving the way for transformative applications in Edge AI, \gls{iot}, \gls{fl}, Industry 4.0, and smart cities. Interoperability of quantization approaches and model compression techniques are often favored in decentralized machine learning approaches and mission critical domains to ensure the safety and reliability of \gls{ai} systems. In this line, the development of efficient compute engines remains a crucial enabler for unlocking the full potential of \gls{ai}/\gls{ml} technologies.

This section presents the preamble to investigate design methodologies for low-power hardware accelerators of \gls{ai}/\gls{ml} algorithms focusing on inference quality, scalability, versatility, and compatibility as design philosophy.

\subsection{AI/ML in Industry 4.0}
\gls{ai} and \gls{ml} play a crucial role in the context of Industry 4.0, which is characterized by the integration of digital technologies into manufacturing and industrial processes to create a more connected, intelligent, and automated environment.

\subsubsection{Industry 4.0}
Since the beginning of industrialization, technological leaps have led to paradigm shifts, now called "industrial revolutions": from mechanization, electrification, and later, digitalization (the so-called 3rd industrial revolution). Based on the advanced digitalization within factories, the combination of Internet technologies and future-oriented technologies in the field of "smart" things (machines and products) seems to result in a new fundamental paradigm shift in industrial production. Emerging from this future expectation, the term "Industry 4.0" was established for an expected "4th industrial revolution"~\cite{lasi2014industry}.


\subsubsection{Internet-of-Things in Industry}
% Context background
To build the emerging environment of Industry 4.0, disruptive technologies are required to handle autonomous communications between all industrial embedded computers throughout the factory and the Internet. Such technologies offer the potential to transform the industry along the entire production chain and stimulate productivity and overall economic growth \cite{espinoza2020estimating}. These technologies include cloud computing, big data, and specially a new generation of \gls{iot} devices fused with \gls{cps}, safety-security, augmented reality, \gls{ml}, and hardware accelerators~\cite{alcacer2019scanning}.

\subsubsection{Artificial Intelligence in Internet-of-Things}
% Particular background
The continuous evolution of \gls{ai} algorithms and \gls{iot} devices has not only made \gls{ai} the major workload running on these embedded devices, but has transformed \gls{ai} into the main approach for industrial solutions, especially in the rise of Industry 4.0~\cite{alcacer2019scanning}. As a result, the term of \gls{iot} has also been redefined as \gls{ai} of Things (AIoT) to emphasize the impact on this technology~\cite{zhang2020empowering}.

There is a clear motivation to run \gls{ai}/\gls{ml} algorithms on \gls{iot} devices because of~\cite{loh20201}:

\begin{itemize}
	\item \textbf{Feasibility of Mission-Critical with Real-Time Processing}. Deploying \gls{ml} models directly on embedded devices, inference can be performed locally without relying on cloud or remote servers. This enables real-time decision-making and faster response times, which is critical for applications such as autonomous vehicles, industrial automation, and robotics.
	\item \textbf{Privacy and Security of Data}. Processing data locally on embedded devices helps preserve data privacy and security. Instead of transmitting sensitive data to external servers, the data stays inside the device, reducing the risk of data breaches or unauthorized access.
	\item \textbf{Offline Operation Capability and Robustness for Stressed Communication}. Embedded devices often work in environments where network connectivity may be limited or intermittent. Locally running \gls{ml} models allow the device to continue to function and make intelligent decisions even when disconnected from the network.
\end{itemize}


\subsection{Approximation in AI/ML}
Based on the error tolerance in \gls{ml} algorithms, a promising solution is approximate computing. This paradigm has been used in a wide range of applications to increase hardware efficiency~\cite{han2013approximate}. For neural network applications, two main approximation strategies are used, namely network compression and classical approximate computing~\cite{bouvier2019spiking}.

\subsubsection{Network Compression and Quantization}
Researchers focusing on embedded applications started lowering the precision of weights and activation maps to shrink the memory footprint of the large number of parameters representing \glspl{ann}, a method known as network quantization. In this manner, reduced bit precision causes a small accuracy loss~\cite{courbariaux2015binaryconnect, han2015deep, hubara2017quantized, rastegari2016xnor}. In addition to quantization, network pruning reduces the model size by removing structural portions of the parameters and its associated computations~\cite{lecun1989optimal,hassibi1992second}. This method has been identified as an effective technique to improve the efficiency of \gls{cnn} for applications with limited computational and energy  budget~\cite{molchanov2016pruning,li2016pruning, liu2018rethinking}. These techniques leverage the intrinsic error-tolerance of neural networks, as well as their ability to recover from accuracy degradation while training.

\subsubsection{Error Tolerance in AI/ML Algorithms}
An algorithm can be regarded as error-tolerant or error-resilient when it provides a result with the required accuracy while utilizing processing components with a certain degree of inaccuracy. There are several reasons why an algorithm/application is tolerant of errors as discussed in~\cite{chippa2013analysis}. These include noisy or redundant data of the algorithm, approximate or probabilistic computations within the algorithm, and a range of acceptable outcomes. This is the case of \gls{ai}/\gls{ml} models.


\subsubsection{Approximate Computing}
%Geneal background
Approximate computing is a design paradigm that is able to tradeoff computation quality (e.g., accuracy) and computational efficiency (e.g., in run-time, chip-area, and/or energy) by exploiting the error resilience of applications/algorithms~\cite{gillani2020exploiting, zhang2015approxann}. Data redundancy of neural networks incorporate a certain degree of resilience against random external and internal perturbations;
for instance, noisy inputs and random hardware errors. This property can be exploited in a cross-layer resilience approach~\cite{carter2010design}: by leveraging error tolerance at algorithmic-level, it can be allowed a certain degree of inaccuracies at the computing-level. This approach consists of designing processing elements that approximate their computation by employing cleverly modified algorithmic logic units~\cite{han2013approximate}.

Approximate computing techniques allow substantial enhancement in processing efficiency with moderated accuracy degradation. Some research papers have shown the feasibility of applying approximate computing to the inference stage of neural networks~\cite{lotrivc2012applicability, han2013approximate, du2014leveraging, mrazek2016design, sarwar2016multiplier, zervakis2021approximate}. Such techniques usually demonstrated small inference accuracy degradation, but significant enhancement in computational performance, chip-area, and energy consumption. Hence, by taking advantage of the intrinsic error-tolerance of neural networks, approximate computing is positioned as a promising approach for \gls{ai}/\gls{ml} computation on resource-limited devices.

% Problem to solve
\section{Problem Statement}
A fundamental problem for the rise of \gls{ai} in Industry 4.0 is the fact that \gls{ml} models, particularly \glspl{cnn} and \glspl{ann}, are highly computational and data intensive. This brings significant challenges across the spectrum of computing hardware, specially in the scope of embedded systems~\cite{venkataramani2016efficient}. The most deployed models and also some of the most computationally and energy expensive are for computer vision using \glspl{cnn}. Compared to the conventional image processing methods, the accuracy of \gls{cnn} has improved significantly that by 2015, a human can no longer beat a computer in image classification~\cite{loh20201}. The early development of \glspl{cnn} before 2016 mainly focused on accuracy improvement without considering computational costs. While accuracy of deep \gls{cnn} for image classification improved 24\% between 2012 and 2016, the demand on hardware resources increased more than $10\times$. Starting from 2017, significant attention was paid to improve hardware efficiency in terms of compute power, memory bandwidth, and power consumption, while maintaining accuracy at a similar level to human perception~\cite{venkataramani2016efficient}.

\subsection{Power Dissipation}
Consequently, the recent breakthroughs in \gls{ai}/\gls{ml} applications have brought significant advancements in neural network processors~\cite{jouppi2017datacenter}. To bring the inference speed to an acceptable level, \gls{asic} with \gls{npu} are becoming ubiquitous in both embedded and general purpose computing. \glspl{npu} perform several tera operations per second in a confined area, as a consequence, they become subject to elevated on-chip power densities that rapidly result in excessive on-chip temperatures during operation~\cite{amrouch2020npu}. Subsequently, the elevated power supply, physical dimensions, heat sink and air cooling requirements demand a balance between the benefits of \gls{ml} against its environmental and financial costs. This outcome is expected on parallel computing techniques, yet unsustainable for resource-constrained devices.
Therefore, radical changes to conventional computing are required in order to sustain and improve performance while satisfying energy and temperature constraints~\cite{gillani2020exploiting}.

\subsection{Aggressive Quantization}
Furthermore, reducing the compute hardware with aggressive quantization such as binary \cite{courbariaux2015binaryconnect}, ternary \cite{lin2015neural}, and mixed precision (2-bit activations and ternary weights) \cite{colangelo2018exploration} typically incur significant accuracy degradation for very low precisions, especially for complex problems~\cite{faraone2019addnet}, such as: semantic segmentation, machine translation, language generation, playing agents, image/music generation, and medical applications.

While aggressive quantization can be beneficial for resource-constrained environments and non-critical applications, careful consideration and a more conservative approach are essential for ensuring the safety and reliability of \gls{ai}/\gls{ml} systems in mission-critical domains. Quantization techniques must be chosen wisely, keeping in mind the specific requirements and constraints of each application.

\subsection{Interoperability}
Aggressive quantization might not be supported by all hardware platforms. Custom hardware accelerators may have limitations on the precision they can handle effectively, limiting the compatibility and portability of aggressively quantized models. Aggressively quantized models may not be compatible with all frameworks, libraries, or \gls{ai} platforms, limiting their interoperability and portability across different environments. In real-world deployment scenarios, there may be constraints and requirements that make aggressive quantization impractical, especially when high accuracy, compatibility, portability, and interoperability are necessary.
%%%%%%%%%%%%%%
\section{Working Hypothesis}
% Alternatives and possible solutions for the problem
Despite its benefits, quantization may lead to a trade-off between model accuracy and hardware efficiency. Aggressive quantization can cause a loss of model accuracy due to information loss from reduced precision. Therefore, finding the right balance between quantization levels and model accuracy becomes a critical challenge in developing efficient hardware accelerators for \gls{ml} applications.

\textit{Introducing custom \gls{fp} computation, with standard \gls{fp} activation maps and significantly reduced \gls{fp} representation for trainable parameters, will lead to improved hardware efficiency in \gls{ml} accelerators, without significant loss in model accuracy.
}

The hypothesis is built on the following key aspects:

\begin{itemize}
	\item \textbf{Reduced Precision Requirement for Weights and Biases}. Neural network models can tolerate lower precision for weights and biases without a substantial decrease in model accuracy~\cite{lai2017deep}. By significantly reducing the bit-width of weights and biases, the memory requirements and computational complexity of the accelerator can be significantly reduced.
	\item \textbf{\gls{fp} Activation Maps}. Retaining higher precision in activation maps prevents significant accuracy degradation during inference.
	\item \textbf{Hardware Efficiency}. The mixed precision approach, combining standard \gls{fp} activation maps and reduced bit-width for weights and biases, is expected to improve the hardware efficiency of ML accelerators~\cite{lai2017deep}. The reduced bit-width for weights and biases will enable faster arithmetic operations and reduce memory bandwidth requirements, leading to more efficient processing in hardware accelerators.
	\item \textbf{Compatibility and Interoperability}. The hardware accelerator should be designed to efficiently handle the combination of different precision levels for weights, biases, and activation maps. Downgrading \gls{fp} from higher precision to lower precision involves rounding or discarding the extra bits. Upgrading \gls{fp} from lower precision to higher precision involves wrapping values in wider bit representations.
	\item \textbf{\gls{qat}}. This helps the model adapt to the mixed precision representation, ensuring that the reduced precision for weights and biases does not cause significant accuracy loss.
\end{itemize}

The dissertation would contribute to the field of hardware-efficient \gls{ml} accelerators by exploring the trade-offs between \gls{fp} precision levels for different hardware components and finding the right balance to achieve improved efficiency without compromising accuracy.

%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Research Objective}
Develop novel design methodologies for low-power neural network accelerators with custom \gls{fp} computation. This research objective encompasses several key aspects that are crucial for advancing the field of low-power neural network accelerators with custom \gls{fp} computation:

\begin{itemize}
	\item \textbf{Custom \gls{fp} Representation}. Investigate novel custom \gls{fp} representation optimized for neural network computations. This involves exploring different bit-widths, exponent formats, or non-standard floating-point representations tailored specifically for neural network workloads.
	\item \textbf{Low-Power Design Techniques}. Investigate low-power design techniques at various levels, including logic-level optimizations and architectural-level approaches to minimize power consumption.
	\item \textbf{Custom \gls{fp} Arithmetic}. Investigate design and implementation of custom arithmetic units that efficiently perform the proposed custom \gls{fp} computations. Special attention shall be given to reducing energy consumption during arithmetic operations.
	\item \textbf{Neural Network-Specific Optimization}. Investigate accelerator architectures specifically for neural network workloads in resource-constrained applications. Low-power techniques like pipe-lining, data quantization, and hardware-specific optimizations are explored to ensure efficiency and \gls{qor}.
	\item \textbf{Quantization and Precision Analysis}. Investigate and present comprehensive analysis of the effects of quantization and reduced precision on model accuracy. \gls{qat} and dynamic precision techniques to maintain or enhance accuracy with lower precision arithmetic.
	\item \textbf{Scalability and Versatility}. Investigate scalability techniques to handle a wide range of neural network models and sizes.
	\item \textbf{Comparison with Other Approaches}. Include comparisons with other low-power neural network accelerators to demonstrate the strengths and uniqueness of the proposed custom \gls{fp} computation techniques.
		\item \textbf{Evaluation and Benchmarking}. Present evaluation and benchmarking against existing state-of-the-art, demonstrate advantages in terms of power efficiency and performance.
	\item \textbf{Real-World Applications}. The objective involves showcasing the practical applicability in real-world low-power and resource-constrained applications, such as sensor analytics.
	\item \textbf{Future Directions}. This dissertation shall provide valuable insights into future research directions for further optimizing low-power neural network accelerators with custom \gls{fp} computation, potential integration with edge devices, and their impact on the broader field of machine learning hardware.
\end{itemize}

Overall, the research objective should address significant challenges in designing efficient hardware accelerators for neural networks, with a focus on reducing power consumption through custom \gls{fp} computation and advancing the state-of-the-art in low-power neural network accelerators.


\section{Scope}\label{chap1.scope}
The scope of this research revolves around enabling energy-efficient and high-quality inference of \gls{sbs} and \gls{cnn} models on resource-constrained applications. This scope presents hardware design methodologies specifically tailored for \gls{sbs} and \gls{cnn} models on \gls{soc} devices with limited computational resources, memory, and power constraints.



\begin{itemize}

\item \textbf{Spike-by-Spike Neural Networks}. \glspl{snn} offer advantageous robustness and the potential to achieve a power efficiency closer to that of the human brain. \glspl{snn} operate reliably using stochastic elements that are inherently non-reliable mechanisms~\cite{mcdonnell2011benefits}. This provides superior resistance against adversary attacks~\cite{ernst2007efficient, Dapello2020.06.16.154542}. Beside robustness, \glspl{snn} have further advantages like the possibility of a more efficient asynchronous parallelization and higher energy efficiency than conventional \glspl{ann}.

The Spike-by-Spike model is on the less realistic side of the \gls{snn} scale of biological realism~\cite{rotermund2019Backpropagation,ernst2007efficient}. Consequently, the hardware complexity of \gls{sbs} network implementations is greatly reduced~\cite{rotermund2018massively}. In spite of this, \gls{sbs} still uses stochastic spikes as a means of transmitting information between populations of neurons and thus retains the advantageous robustness of \glspl{snn}. A significant research effort has been done in \gls{snn} accelerators, see e.g.~\cite{roy2019towards,bouvier2019spiking,
	young2019review,TrueNorth_Trans15,Spinnaker_Trans13,davies2018loihi}.

However, hardware accelerators that focus on \gls{sbs} have only been partially investigated so far~\cite{rotermund2018massively}. Enhanced \gls{sbs} accelerators will have a double impact. From scientific and application point of view, they will facilitate fundamental research for neuroscience~\cite{ernst2007efficient,rotermund2019recurrentsbs, dayan2001theoretical} and contribute to the deployment of robust neural networks in small embedded systems~\cite{nevarez2020accelerator}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item \textbf{Convolutional Neural Networks}. \glspl{cnn} represent the essential building blocks in 2D pattern analytics. Sensor-based applications such as mechanical fault detection \cite{li2019sensor,dong2018rolling}, structural health monitoring \cite{nagayama2007structural}, \gls{har} \cite{wang2019deep}, hazardous gas detection \cite{kim2017hazardous} have been powered by \gls{cnn} models in industry and academia. \gls{cnn} models provide advantages such as local dependency, scale invariance, and noise resilience in analytics \cite{du2014leveraging}. However, these models are computationally intensive and power-hungry. This is particularly challenging for low-power embedded applications, specially in the field of \gls{iot}. As a result, numerous commercial \gls{asic} and \gls{fpga} accelerators have been proposed, these are targeting both \gls{hpc} for data-centers and embedded systems applications.

However, most accelerators have been implemented to target mid- to high-range \glspl{fpga} for computationally intensive \gls{cnn} models such as AlexNet, VGG-16, and ResNet-18. The main drawbacks of these implementations are power supply demands, physical dimensions, heat sink requirements, air cooling, and a resulting high price. In some cases, these implementations are not feasible for ubiquitous low-power/resource-constrained applications. Furthermore, reducing the compute hardware with aggressive quantization such as binary \cite{courbariaux2015binaryconnect}, ternary \cite{lin2015neural}, and mixed precision (2-bit activations and ternary weights) \cite{colangelo2018exploration} typically incur significant accuracy degradation for very low precisions, especially for complex problems~\cite{faraone2019addnet}.

\end{itemize}

\section{Contributions}
This research contributes to hardware design methodologies for custom \gls{fp} neural network accelerators for high quality of inference in
 low-power embedded systems. The contributions for \gls{sbs} and \gls{cnn} hardware accelerators are listed below:

\subsection{Spike-by-Spike Neural Networks}
\begin{enumerate}
	\item It is presented a hardware component for \gls{fp} vector dot-product approximation. This design increases the performance of computation by performing element-wise multiplication with a quality configurable design based on bit truncation and denormalized accumulation.
	\item It is presented a design exploration with the proposed dot-product approximation using synaptic weight vectors with custom \gls{fp} and logarithmic representation. The run-time, accuracy degradation, resource utilization, and power dissipation are evaluated. Experimental results demonstrate $20.5\times$ latency enhancement versus embedded \gls{cpu} (ARM Cortex-A9 at \unit[666]{MHz}), and less than $0.5\%$ of accuracy degradation on a handwritten digit recognition task (MNIST).
	\item It is proposed a noise tolerance plot as quality monitor, which serves as an intuitive visual model to provide insights into the accuracy degradation of \gls{sbs} networks under approximate processing effects.
	\item The presented design for \gls{fp} dot-product approximation is adaptable as a building block for other error resilient applications (e.g., image/video processing).
\end{enumerate}


\subsection{Convolutional Neural Networks}
\begin{enumerate}
	\item It is proposed the \gls{hf6} quantization and its dedicated hardware architecture. This design features an optimized hardware \gls{mac} by reducing the mantissa multiplication to a multiplexer-adder operation. This approach exploits the intrinsic error tolerance of \gls{ann} to further reduce the hardware design with approximation. To preserve model accuracy, it is presented a quantization-aware training method, which in some cases improves accuracy based on the regularization effect.
	
	\item It is developed a custom hardware/software co-design framework for \gls{cnn} sensor analytics applications on low-power and resource-constrained embedded \glspl{fpga}. This architecture integrates TensorFlow Lite.
	
	\item It is presented a customizable tensor processor as a dedicated hardware for \gls{hf6}. This design computes \emph{Conv2D} tensor operations employing a pipelined vector dot-product with approximate computing and parametrized on-chip memory utilization.
	
	\item The potential of this approach is demonstrated with a \gls{cnn}-regression model for anomaly localization in structural health monitoring based on acoustic emissions. A hardware design exploration is addressed evaluating accuracy, compute performance, hardware resource utilization, and energy consumption.
\end{enumerate}

\section{Publications}
The outcome of this dissertation, including the collaborative works with our research partners is a list of publications including \cite{nevarez2020accelerator, nevarez2021accelerating, yn2022cnnsensor}. In the following, a complete list of the related publications are itemized.

\begin{enumerate}
	
	\subsubsection*{Journal Articles}
	
	\item \textbf{Yarib Nevarez}, David Rotermund, Klaus R Pawelzik, and Alberto Garcia-Ortiz, "Accelerating Spike-by-Spike Neural Networks on FPGA With Hybrid Custom Floating-Point and Logarithmic Dot-Product Approximation," 
	\newblock IEEE Access, vol. 9, pp. 80603--80620, May 2021, doi: 10.1109/ACCESS.2021.3085216.  
	
	\item \textbf{Yarib Nevarez}, Andreas Beering, Amir Najafi, Ardalan Najafi, Wanli Yu, Yizhi Chen, Karl-Ludwig Krieger, and Alberto Garcia-Ortiz, "CNN Sensor Analytics With Hybrid-Float6 Quantization on Low-Power Embedded FPGAs," 
	\newblock IEEE Access, vol. 11, pp. 4852--4868, January 2023, doi: 10.1109/ACCESS.2023.3235866.

	
	\subsubsection*{Conference Proceedings}
	
	\item \textbf{Yarib Nevarez}, Alberto Garcia-Ortiz, David Rotermund, and Klaus R Pawelzik, "Accelerator framework of spike-by-spike neural networks for inference and incremental learning in embedded systems,"
	\newblock 2020 9th International Conference on Modern Circuits and Systems Technologies (MOCAST), Bremen, 2020, pp. 1--5, doi: 10.1109/MOCAST49295.2020.9200288.
	
	\item Wanli Yu, Ardalan Najafi, \textbf{Yarib Nevarez}, Yanqiu Huang and Alberto Garcia-Ortiz, "TAAC: Task Allocation Meets Approximate Computing for Internet of Things," 
	\newblock 2020 IEEE International Symposium on Circuits and Systems (ISCAS), Sevilla, 2020, pp. 1-5, doi: 10.1109/ISCAS45731.2020.9180895.
	
	\item Amir Najafi, Ardalan Najafi, \textbf{Yarib Nevarez} and Alberto Garcia-Ortiz, "Learning-Based On-Chip Parallel Interconnect Delay Estimation," 
	\newblock 2022 11th International Conference on Modern Circuits and Systems Technologies (MOCAST), Bremen, 2022, pp. 1--5, doi: 10.1109/MOCAST49295.2020.9200288.
	
	\item Yizhi Chen, \textbf{Yarib Nevarez}, Zhonghai Lu, and Alberto Garcia-Ortiz, "Accelerating Non-Negative Matrix Factorization on Embedded FPGA with Hybrid Logarithmic Dot-Product Approximation," 
	\newblock 2022 IEEE 15th International Symposium on Embedded Multicore/Many-core Systems-on-Chip (MCSoC), Malaysia, 2022, pp. 239--246, doi: 10.1109/MCSoC57363.2022.00070.
	
	\item Ardalan Najafi, Wanli Yu, \textbf{Yarib Nevarez}, Amir Najafi, Andreas Beering, Karl-Ludwig Krieger, and Alberto Garcia-Ortiz, "Acoustic Emission Source Localization using Approximate Discrete Wavelet Transform," \newblock 2023 12th International Conference on Modern Circuits and Systems Technologies (MOCAST), Bremen, 2023, pp. X--X, doi: XX.XXXX/MOCASTXXXXX.XXXX.XXXXXXX.
	
\end{enumerate}

\section{Dissertation Outline}

This dissertation is organized in three main parts: an introduction, where
the state of the art and related background are stated; a central core, where the proposed design methodologies and validation are presented; and a final part with the conclusion. More precisely:

\begin{enumerate}[I]
	\item \textbf{Introduction}: Chapter~\ref{chap.background} introduces the background related to \gls{sbs}, \gls{cnn}, and \gls{fp} number representation.
	\item \textbf{Core}: the proposed hardware design methodologies for \gls{sbs} and \gls{cnn} accelerators are presented in Chapter~\ref{chap.sbs} and Chapter~\ref{chap.cnn}, respectively.
	\item \textbf{Conclusions}: the final conclusions are presented in Chapter~\ref{chap.conclusion}.
\end{enumerate}