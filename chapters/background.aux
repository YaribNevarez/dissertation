\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{15}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {xchapter}{Background}{15}{chapter.2}\protected@file@percent }
\@writefile{lot}{\contentsline {xchapter}{Background}{15}{chapter.2}\protected@file@percent }
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chap.background}{{2}{15}{Background}{chapter.2}{}}
\newlabel{chap.background@cref}{{[chapter][2][]2}{[1][15][]15}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Introduction}{17}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Neural Networks: Fundamentals}{18}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Architecture}{18}{subsection.2.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Nodes (Neurons)}{18}{subsection.2.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Layers in a Neural Network}{18}{subsection.2.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.4}Weights and Biases}{19}{subsection.2.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.5}Activation Functions}{19}{subsection.2.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Evolution of Neural Networks}{20}{section.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Perceptrons}{20}{subsection.2.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Multi-layer Perceptrons (MLP)}{20}{subsection.2.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Deep Neural Networks (DNNs)}{20}{subsection.2.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.4}Convolutional Neural Networks (CNNs)}{21}{subsection.2.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Motivation: The Limitations of CPUs for Neural Network Processing}{21}{section.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Parallelism}{21}{subsection.2.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Memory Bottlenecks}{21}{subsection.2.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}Energy Efficiency}{22}{subsection.2.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.4}Flexibility vs. Specialization}{22}{subsection.2.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Overview of Hardware Accelerators for Neural Network Processing}{22}{section.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}Graphics Processing Units (GPUs)}{22}{subsection.2.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}Field-Programmable Gate Arrays (FPGAs)}{23}{subsection.2.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.3}Application-Specific Integrated Circuits (ASICs)}{23}{subsection.2.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.4}Tensor Processing Units (TPUs)}{24}{subsection.2.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.6}The Quest for Low-Power Neural Computing}{24}{section.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.1}Power Reduction Techniques in Neural Network Accelerators}{24}{subsection.2.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Approximate Computing}{25}{section*.12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Quantization}{25}{section*.13}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Custom Floating-Point Computation}{26}{section*.14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.2}Relationship Between Computational Precision and Power Consumption}{26}{subsection.2.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.7}IEEE Standard for Floating-Point Arithmetic}{27}{section.2.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.1}Structure of IEEE 754 Representation}{27}{subsection.2.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.2}Benefits of IEEE 754 Standard}{28}{subsection.2.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.3}Limitations of IEEE 754 Standard}{28}{subsection.2.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.8}Errors and Limitations in Floating-Point Computation}{29}{section.2.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8.1}Types of Floating-Point Errors}{29}{subsection.2.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8.2}Implications in Neural Networks}{30}{subsection.2.8.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.9}Traditional Floating-Point Formats for Neural Networks}{30}{section.2.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.9.1}Inherent Inefficiencies}{30}{subsection.2.9.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.9.2}Power and Area Costs}{31}{subsection.2.9.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.9.3}Latency Concerns}{31}{subsection.2.9.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.9.4}Customization Potential}{31}{subsection.2.9.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.10}Custom Floating-Point Formats for Neural Network Computations}{32}{section.2.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.10.1}Trade-offs of Custom Floating-Point Formats}{32}{subsection.2.10.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.11}State-of-the-Art Low-Power Neural Network Accelerators}{32}{section.2.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.11.1}Accelerator Overview}{33}{subsection.2.11.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.12}State-of-the-Art Low-Power Accelerators with Custom Floating-Point Formats}{33}{section.2.12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.12.1}Accelerator Overview}{33}{subsection.2.12.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.13}Gaps in Existing Solutions and Motivation for Further Exploration}{34}{section.2.13}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.13.1}Limitations of Current Approaches}{34}{subsection.2.13.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.13.2}Need for Further Exploration}{34}{subsection.2.13.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.13.3}Research Questions and Objectives}{35}{subsection.2.13.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.14}Conclusion}{35}{section.2.14}\protected@file@percent }
\citation{ernst2007efficient}
\@writefile{toc}{\contentsline {section}{\numberline {2.15}Spike-by-Spike Neural Networks}{36}{section.2.15}\protected@file@percent }
\newlabel{sec:sbs}{{2.15}{36}{Spike-by-Spike Neural Networks}{section.2.15}{}}
\newlabel{sec:sbs@cref}{{[section][15][2]2.15}{[1][36][]36}}
\citation{ernst2007efficient}
\citation{rotermund2019Backpropagation}
\citation{izhikevich2004model}
\newlabel{eq:sbs_update}{{2.11}{37}{Spike-by-Spike Neural Networks}{equation.2.15.11}{}}
\newlabel{eq:sbs_update@cref}{{[section][15][2]2.15}{[1][36][]37}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.15.1}Basic Network Overview}{37}{subsection.2.15.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.15.2}Computational Cost}{37}{subsection.2.15.2}\protected@file@percent }
\citation{lecun1998mnist}
\citation{rotermund2019Backpropagation}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.15.3}Error Tolerance}{38}{subsection.2.15.3}\protected@file@percent }
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces SbS layer update.\relax }}{38}{algocf.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{alg:sbs}{{1}{38}{Basic Network Overview}{algocf.1}{}}
\newlabel{alg:sbs@cref}{{[algocf][1][]1}{[1][37][]38}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces \gls {sbs} network architecture for handwritten digit classification task.\relax }}{38}{figure.caption.16}\protected@file@percent }
\newlabel{fig:sbs_network}{{2.1}{38}{\gls {sbs} network architecture for handwritten digit classification task.\relax }{figure.caption.16}{}}
\newlabel{fig:sbs_network@cref}{{[figure][1][2]2.1}{[1][37][]38}}
\citation{gu2018recent}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces \gls {sbs} network architecture for handwritten digit classification task.\relax }}{39}{table.caption.17}\protected@file@percent }
\newlabel{tab:sbs_network}{{2.1}{39}{\gls {sbs} network architecture for handwritten digit classification task.\relax }{table.caption.17}{}}
\newlabel{tab:sbs_network@cref}{{[table][1][2]2.1}{[1][37][]39}}
\@writefile{toc}{\contentsline {section}{\numberline {2.16}Conv2D Tensor Operation}{39}{section.2.16}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces \gls {sbs} \glspl {ip_sbs} as independent computational entities, (a) illustrates an input layer with a massive amount of \glspl {ip_sbs} operating as independent computational entities, (b) shows a hidden layer with an arbitrary amount of \glspl {ip_sbs} as independent computational entities, (c) exhibits a set of neurons grouped in an \gls {ip_sbs}.\relax }}{39}{figure.caption.18}\protected@file@percent }
\newlabel{fig:SbS_layer}{{2.2}{39}{\gls {sbs} \glspl {ip_sbs} as independent computational entities, (a) illustrates an input layer with a massive amount of \glspl {ip_sbs} operating as independent computational entities, (b) shows a hidden layer with an arbitrary amount of \glspl {ip_sbs} as independent computational entities, (c) exhibits a set of neurons grouped in an \gls {ip_sbs}.\relax }{figure.caption.18}{}}
\newlabel{fig:SbS_layer@cref}{{[figure][2][2]2.2}{[1][38][]39}}
\citation{goodfellow2016deep}
\newlabel{eq:conv2D}{{2.12}{40}{Conv2D Tensor Operation}{equation.2.16.12}{}}
\newlabel{eq:conv2D@cref}{{[section][16][2]2.16}{[1][40][]40}}
\@writefile{toc}{\contentsline {section}{\numberline {2.17}Floating-point Number Representation}{40}{section.2.17}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces (a) Performance classification of \gls {sbs} NN versus equivalent \gls {cnn}, and (b) example of the first pattern in the MNIST test data set with different amounts of positive additive uniformly distributed noise.\relax }}{40}{figure.caption.19}\protected@file@percent }
\newlabel{fig:robustnes_sbs}{{2.3}{40}{(a) Performance classification of \gls {sbs} NN versus equivalent \gls {cnn}, and (b) example of the first pattern in the MNIST test data set with different amounts of positive additive uniformly distributed noise.\relax }{figure.caption.19}{}}
\newlabel{fig:robustnes_sbs@cref}{{[figure][3][2]2.3}{[1][39][]40}}
\citation{zuras2008ieee}
\newlabel{eq:float}{{2.13}{41}{Floating-point Number Representation}{equation.2.17.13}{}}
\newlabel{eq:float@cref}{{[section][17][2]2.17}{[1][40][]41}}
\newlabel{eq:float_bias}{{2.14}{41}{Floating-point Number Representation}{equation.2.17.14}{}}
\newlabel{eq:float_bias@cref}{{[section][17][2]2.17}{[1][41][]41}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Floating-point number representation.\relax }}{41}{figure.caption.20}\protected@file@percent }
\newlabel{fig:floating}{{2.4}{41}{Floating-point number representation.\relax }{figure.caption.20}{}}
\newlabel{fig:floating@cref}{{[figure][4][2]2.4}{[1][41][]41}}
\newlabel{eq:float_subnorm}{{2.15}{42}{Floating-point Number Representation}{equation.2.17.15}{}}
\newlabel{eq:float_subnorm@cref}{{[section][17][2]2.17}{[1][42][]42}}
\@setckpt{./chapters/background}{
\setcounter{page}{43}
\setcounter{equation}{15}
\setcounter{enumi}{3}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{17}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{4}
\setcounter{table}{1}
\setcounter{Item}{21}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{0}
\setcounter{float@type}{8}
\setcounter{parentequation}{0}
\setcounter{etoc@tocid}{1}
\setcounter{etoc@tocdepth}{4}
\setcounter{lstnumber}{1}
\setcounter{caption@flags}{0}
\setcounter{continuedfloat}{0}
\setcounter{KVtest}{0}
\setcounter{subfigure}{0}
\setcounter{subfigure@save}{0}
\setcounter{lofdepth}{1}
\setcounter{subtable}{0}
\setcounter{subtable@save}{0}
\setcounter{lotdepth}{1}
\setcounter{r@tfl@t}{0}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
\setcounter{mtc}{2}
\setcounter{minitocdepth}{2}
\setcounter{ptc}{0}
\setcounter{parttocdepth}{2}
\setcounter{su@anzahl}{0}
\setcounter{AlgoLine}{0}
\setcounter{algocfline}{1}
\setcounter{algocfproc}{1}
\setcounter{algocf}{1}
\setcounter{ALC@unique}{15}
\setcounter{ALC@line}{15}
\setcounter{ALC@rem}{0}
\setcounter{ALC@depth}{0}
\setcounter{theorem}{0}
\setcounter{@pps}{0}
\setcounter{@ppsavesec}{0}
\setcounter{@ppsaveapp}{0}
\setcounter{section@level}{1}
\setcounter{lstlisting}{0}
\setcounter{minilofdepth}{2}
\setcounter{minilotdepth}{2}
\setcounter{partlofdepth}{2}
\setcounter{partlotdepth}{2}
\setcounter{sectlofdepth}{2}
\setcounter{sectlotdepth}{2}
}
